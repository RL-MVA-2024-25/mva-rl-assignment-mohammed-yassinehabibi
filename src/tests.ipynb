{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from evaluate import evaluate_HIV, evaluate_HIV_population\n",
    "from train import ProjectAgent  # Replace DummyAgent with your agent implementation\n",
    "from statistics import mean\n",
    "from functools import partial\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from env_hiv import HIVPatient\n",
    "from interface import Agent\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import time\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "import ffmpeg\n",
    "import seaborn as sns\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=TimeLimit(HIVPatient(), max_episode_steps=200)\n",
    "'''nb_episodes = 100\n",
    "states = np.zeros((nb_episodes*200,env.observation_space.shape[0]))\n",
    "for i in range(nb_episodes):\n",
    "    s,_ = env.reset()\n",
    "    for j in range(200):\n",
    "        s2,r,d,trunc,_ = env.step(env.action_space.sample())\n",
    "        states[i*200+j] = s2\n",
    "    print(i, end=', ')\n",
    "\n",
    "states_means = states[:58*200].mean(axis=0)\n",
    "states_stds = states[:58*200].std(axis=0)\n",
    "#save them\n",
    "np.save('states_means.npy', states_means)\n",
    "np.save('states_stds.npy', states_stds)\n",
    "#load them\n",
    "states_means = np.load('states_means.npy')\n",
    "states_stds = np.load('states_stds.npy')''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import ReplayBuffer, greedy_action, evaluate_agent, dqn_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode   1, epsilon   1.00, batch size   200, episode return 10.3M, loss 39189.9\n",
      "Evaluation deterministic reward 6.8M\n",
      "Episode   2, epsilon   1.00, batch size   400, episode return 11.0M, loss 430363.0\n",
      "Episode   3, epsilon   1.00, batch size   600, episode return  9.2M, loss 1643426.2\n",
      "Episode   4, epsilon   0.96, batch size   800, episode return 10.4M, loss 3523872.8\n",
      "Episode   5, epsilon   0.92, batch size  1000, episode return  9.1M, loss 4551970.0\n",
      "Episode   6, epsilon   0.88, batch size  1200, episode return  8.8M, loss 5777839.0\n",
      "Episode   7, epsilon   0.84, batch size  1400, episode return  8.9M, loss 3334394.5\n",
      "Episode   8, epsilon   0.80, batch size  1600, episode return  7.7M, loss 2015005.1\n",
      "Episode   9, epsilon   0.76, batch size  1800, episode return 14.4M, loss 1441623.5\n",
      "Episode  10, epsilon   0.72, batch size  2000, episode return 16.5M, loss 1683770.2\n",
      "Episode  11, epsilon   0.68, batch size  2200, episode return  8.9M, loss 819838.5\n",
      "Episode  12, epsilon   0.64, batch size  2400, episode return  7.4M, loss 1008503.0\n",
      "Episode  13, epsilon   0.60, batch size  2600, episode return  8.9M, loss 842637.7\n",
      "Episode  14, epsilon   0.56, batch size  2800, episode return  8.6M, loss 817532.2\n",
      "Episode  15, epsilon   0.52, batch size  3000, episode return  7.6M, loss 524387.5\n",
      "Episode  16, epsilon   0.49, batch size  3200, episode return 12.8M, loss 863372.2\n",
      "Episode  17, epsilon   0.45, batch size  3400, episode return 16.5M, loss 933596.9\n",
      "Episode  18, epsilon   0.41, batch size  3600, episode return  7.4M, loss 1133727.8\n",
      "Episode  19, epsilon   0.37, batch size  3800, episode return  9.7M, loss 1192111.0\n",
      "Episode  20, epsilon   0.33, batch size  4000, episode return  6.3M, loss 1292580.4\n",
      "Episode  21, epsilon   0.29, batch size  4200, episode return 12.6M, loss 740233.6\n",
      "Episode  22, epsilon   0.25, batch size  4400, episode return 11.0M, loss 832513.8\n",
      "Episode  23, epsilon   0.21, batch size  4600, episode return 11.3M, loss 1071619.9\n",
      "Episode  24, epsilon   0.17, batch size  4800, episode return 14.9M, loss 1305213.8\n",
      "Episode  25, epsilon   0.13, batch size  5000, episode return  6.5M, loss 684385.4\n",
      "Episode  26, epsilon   0.09, batch size  5200, episode return 13.1M, loss 492923.0\n",
      "Episode  27, epsilon   0.05, batch size  5400, episode return 18.8M, loss 443265.6\n",
      "Episode  28, epsilon   0.01, batch size  5600, episode return 11.8M, loss 313722.2\n",
      "Episode  29, epsilon   0.01, batch size  5800, episode return  7.9M, loss 267480.2\n",
      "Episode  30, epsilon   0.01, batch size  6000, episode return  7.5M, loss 185773.2\n",
      "Episode  31, epsilon   0.01, batch size  6200, episode return  7.2M, loss 209495.9\n",
      "Episode  32, epsilon   0.01, batch size  6400, episode return 12.4M, loss 112398.0\n",
      "Episode  33, epsilon   0.01, batch size  6600, episode return 14.8M, loss 60518.7\n",
      "Episode  34, epsilon   0.01, batch size  6800, episode return  3.3M, loss 47918.5\n",
      "Episode  35, epsilon   0.01, batch size  7000, episode return  6.3M, loss 43505.6\n",
      "Episode  36, epsilon   0.01, batch size  7200, episode return  5.7M, loss 18884.2\n",
      "Episode  37, epsilon   0.01, batch size  7400, episode return  6.8M, loss 12053.7\n",
      "Evaluation deterministic reward 15.0M\n",
      "Episode  38, epsilon   0.01, batch size  7600, episode return 38.8M, loss 8993.8\n",
      "Episode  39, epsilon   0.01, batch size  7800, episode return  9.7M, loss 2888.0\n",
      "Episode  40, epsilon   0.01, batch size  8000, episode return  6.7M, loss 3061.6\n",
      "Episode  41, epsilon   0.01, batch size  8200, episode return 14.6M, loss 2627.5\n",
      "Episode  42, epsilon   0.01, batch size  8400, episode return 15.2M, loss 1510.7\n",
      "Episode  43, epsilon   0.01, batch size  8600, episode return 10.0M, loss 1056.3\n",
      "Episode  44, epsilon   0.01, batch size  8800, episode return 18.6M, loss 2576.0\n",
      "Episode  45, epsilon   0.01, batch size  9000, episode return 25.1M, loss 1638.4\n",
      "Episode  46, epsilon   0.01, batch size  9200, episode return 15.6M, loss 1131.3\n",
      "Episode  47, epsilon   0.01, batch size  9400, episode return 27.2M, loss 1915.2\n",
      "Evaluation deterministic reward 19.0M\n",
      "Episode  48, epsilon   0.01, batch size  9600, episode return 24.0M, loss 1027.1\n",
      "Evaluation deterministic reward 22.1M\n",
      "Episode  49, epsilon   0.01, batch size  9800, episode return 20.0M, loss 848.8\n",
      "Episode  50, epsilon   0.01, batch size 10000, episode return 29.4M, loss 613.1\n",
      "Episode  51, epsilon   0.01, batch size 10200, episode return 43.8M, loss 1019.7\n",
      "Episode  52, epsilon   0.01, batch size 10400, episode return 30.4M, loss 501.3\n",
      "Episode  53, epsilon   0.01, batch size 10600, episode return 16.8M, loss 1918.0\n",
      "Episode  54, epsilon   0.01, batch size 10800, episode return 38.0M, loss 473.7\n",
      "Episode  55, epsilon   0.01, batch size 11000, episode return 15.1M, loss 1722.8\n",
      "Episode  56, epsilon   0.01, batch size 11200, episode return 47.9M, loss 2477.5\n",
      "Episode  57, epsilon   0.01, batch size 11400, episode return 15.5M, loss 827.3\n",
      "Episode  58, epsilon   0.01, batch size 11600, episode return 19.9M, loss 566.0\n",
      "Episode  59, epsilon   0.01, batch size 11800, episode return 27.1M, loss 925.8\n",
      "Episode  60, epsilon   0.01, batch size 12000, episode return 23.3M, loss 638.7\n",
      "Episode  61, epsilon   0.01, batch size 12200, episode return 19.9M, loss 944.0\n",
      "Episode  62, epsilon   0.01, batch size 12400, episode return 18.2M, loss 1114.6\n",
      "Episode  63, epsilon   0.01, batch size 12600, episode return 28.0M, loss 620.5\n",
      "Episode  64, epsilon   0.01, batch size 12800, episode return 24.1M, loss 503.3\n",
      "Episode  65, epsilon   0.01, batch size 13000, episode return 13.6M, loss 480.2\n",
      "Evaluation deterministic reward 22.8M\n",
      "Episode  66, epsilon   0.01, batch size 13200, episode return 16.2M, loss 2190.6\n",
      "Episode  67, epsilon   0.01, batch size 13400, episode return 46.3M, loss 1095.9\n",
      "Episode  68, epsilon   0.01, batch size 13600, episode return 37.3M, loss 606.6\n",
      "Episode  69, epsilon   0.01, batch size 13800, episode return 41.0M, loss 780.3\n",
      "Episode  70, epsilon   0.01, batch size 14000, episode return 11.3M, loss 1121.5\n",
      "Episode  71, epsilon   0.01, batch size 14200, episode return 14.2M, loss 667.7\n",
      "Episode  72, epsilon   0.01, batch size 14400, episode return 26.8M, loss 833.5\n",
      "Episode  73, epsilon   0.01, batch size 14600, episode return 24.8M, loss 584.2\n",
      "Episode  74, epsilon   0.01, batch size 14800, episode return 12.4M, loss 1086.2\n",
      "Episode  75, epsilon   0.01, batch size 15000, episode return 76.2M, loss 966.0\n",
      "Episode  76, epsilon   0.01, batch size 15200, episode return  9.2M, loss 475.5\n",
      "Episode  77, epsilon   0.01, batch size 15400, episode return 23.6M, loss 1087.4\n",
      "Episode  78, epsilon   0.01, batch size 15600, episode return 19.0M, loss 1179.4\n",
      "Episode  79, epsilon   0.01, batch size 15800, episode return 58.3M, loss 1279.3\n",
      "Episode  80, epsilon   0.01, batch size 16000, episode return 29.4M, loss 521.3\n",
      "Episode  81, epsilon   0.01, batch size 16200, episode return 23.3M, loss 862.1\n",
      "Episode  82, epsilon   0.01, batch size 16400, episode return 18.9M, loss 755.2\n",
      "Episode  83, epsilon   0.01, batch size 16600, episode return 20.3M, loss 518.2\n",
      "Episode  84, epsilon   0.01, batch size 16800, episode return 51.4M, loss 798.3\n",
      "Episode  85, epsilon   0.01, batch size 17000, episode return 23.8M, loss 417.1\n",
      "Evaluation deterministic reward 22.8M\n",
      "Episode  86, epsilon   0.01, batch size 17200, episode return 11.8M, loss 561.8\n",
      "Evaluation deterministic reward 25.8M\n",
      "Episode  87, epsilon   0.01, batch size 17400, episode return  9.2M, loss 823.5\n",
      "Episode  88, epsilon   0.01, batch size 17600, episode return 20.8M, loss 506.1\n",
      "Episode  89, epsilon   0.01, batch size 17800, episode return 52.0M, loss 440.3\n",
      "Episode  90, epsilon   0.01, batch size 18000, episode return 32.6M, loss 732.5\n",
      "Episode  91, epsilon   0.01, batch size 18200, episode return 20.6M, loss 267.2\n",
      "Episode  92, epsilon   0.01, batch size 18400, episode return 19.0M, loss 624.0\n",
      "Episode  93, epsilon   0.01, batch size 18600, episode return 18.7M, loss 505.8\n",
      "Episode  94, epsilon   0.01, batch size 18800, episode return 15.8M, loss 472.5\n",
      "Evaluation deterministic reward 33.3M\n",
      "Episode  95, epsilon   0.01, batch size 19000, episode return 11.9M, loss 370.0\n",
      "Episode  96, epsilon   0.01, batch size 19200, episode return 15.2M, loss 988.6\n",
      "Episode  97, epsilon   0.01, batch size 19400, episode return 33.7M, loss 399.3\n",
      "Episode  98, epsilon   0.01, batch size 19600, episode return 59.3M, loss 603.5\n",
      "Evaluation deterministic reward 35.4M\n",
      "Episode  99, epsilon   0.01, batch size 19800, episode return 23.9M, loss 824.0\n",
      "Episode 100, epsilon   0.01, batch size 20000, episode return 46.2M, loss 719.6\n",
      "Episode 101, epsilon   0.01, batch size 20200, episode return 23.8M, loss 574.6\n",
      "Episode 102, epsilon   0.01, batch size 20400, episode return 21.1M, loss 561.3\n",
      "Episode 103, epsilon   0.01, batch size 20600, episode return 34.9M, loss 540.8\n",
      "Episode 104, epsilon   0.01, batch size 20800, episode return 24.6M, loss 228.2\n",
      "Episode 105, epsilon   0.01, batch size 21000, episode return 18.4M, loss 476.3\n",
      "Episode 106, epsilon   0.01, batch size 21200, episode return 40.5M, loss 365.6\n",
      "Episode 107, epsilon   0.01, batch size 21400, episode return 28.3M, loss 484.1\n",
      "Episode 108, epsilon   0.01, batch size 21600, episode return 21.8M, loss 245.8\n",
      "Episode 109, epsilon   0.01, batch size 21800, episode return 46.3M, loss 540.3\n",
      "Evaluation deterministic reward 44.9M\n",
      "Episode 110, epsilon   0.01, batch size 22000, episode return 87.2M, loss 297.8\n",
      "Episode 111, epsilon   0.01, batch size 22200, episode return 54.6M, loss 617.8\n",
      "Episode 112, epsilon   0.01, batch size 22400, episode return 55.8M, loss 712.1\n",
      "Episode 113, epsilon   0.01, batch size 22600, episode return 57.4M, loss 706.9\n",
      "Episode 114, epsilon   0.01, batch size 22800, episode return 34.7M, loss 226.4\n",
      "Episode 115, epsilon   0.01, batch size 23000, episode return 69.1M, loss 221.2\n",
      "Evaluation deterministic reward 77.4M\n",
      "Episode 116, epsilon   0.01, batch size 23200, episode return 47.2M, loss 165.5\n",
      "Episode 117, epsilon   0.01, batch size 23400, episode return 71.2M, loss 404.6\n",
      "Evaluation deterministic reward 84.3M\n",
      "Episode 118, epsilon   0.01, batch size 23600, episode return 47.6M, loss 261.6\n",
      "Episode 119, epsilon   0.01, batch size 23800, episode return 125.1M, loss 502.6\n",
      "Evaluation deterministic reward 405.7M\n",
      "Episode 120, epsilon   0.01, batch size 24000, episode return 66.3M, loss 657.7\n",
      "Episode 121, epsilon   0.01, batch size 24200, episode return 53.6M, loss 375.2\n",
      "Episode 122, epsilon   0.01, batch size 24400, episode return 65.0M, loss 397.1\n",
      "Episode 123, epsilon   0.01, batch size 24600, episode return 70.0M, loss 142.4\n",
      "Episode 124, epsilon   0.01, batch size 24800, episode return 92.5M, loss 476.6\n",
      "Episode 125, epsilon   0.01, batch size 25000, episode return 69.4M, loss 357.9\n",
      "Episode 126, epsilon   0.01, batch size 25200, episode return 2453.1M, loss 726.6\n",
      "Episode 127, epsilon   0.01, batch size 25400, episode return 31.9M, loss 3137.7\n",
      "Episode 128, epsilon   0.01, batch size 25600, episode return 27.0M, loss 2548.6\n",
      "Episode 129, epsilon   0.01, batch size 25800, episode return 66.2M, loss 2017.4\n",
      "Episode 130, epsilon   0.01, batch size 26000, episode return 73.0M, loss 1070.1\n",
      "Episode 131, epsilon   0.01, batch size 26200, episode return 68.2M, loss 423.0\n",
      "Episode 132, epsilon   0.01, batch size 26400, episode return 63.9M, loss 931.7\n",
      "Episode 133, epsilon   0.01, batch size 26600, episode return 62.1M, loss 842.4\n",
      "Episode 134, epsilon   0.01, batch size 26800, episode return 32.8M, loss 448.3\n",
      "Episode 135, epsilon   0.01, batch size 27000, episode return 74.6M, loss 952.1\n",
      "Episode 136, epsilon   0.01, batch size 27200, episode return 82.7M, loss 381.8\n",
      "Episode 137, epsilon   0.01, batch size 27400, episode return 64.1M, loss 378.7\n",
      "Episode 138, epsilon   0.01, batch size 27600, episode return 62.3M, loss 586.4\n",
      "Episode 139, epsilon   0.01, batch size 27800, episode return 51.2M, loss 429.1\n",
      "Episode 140, epsilon   0.01, batch size 28000, episode return 51.4M, loss 448.1\n",
      "Episode 141, epsilon   0.01, batch size 28200, episode return 52.1M, loss 466.5\n",
      "Episode 142, epsilon   0.01, batch size 28400, episode return 108.9M, loss 213.4\n",
      "Episode 143, epsilon   0.01, batch size 28600, episode return 202.9M, loss 151.0\n",
      "Episode 144, epsilon   0.01, batch size 28800, episode return 96.8M, loss 286.5\n",
      "Episode 145, epsilon   0.01, batch size 29000, episode return 81.1M, loss 429.1\n",
      "Episode 146, epsilon   0.01, batch size 29200, episode return 224.6M, loss 306.0\n",
      "Episode 147, epsilon   0.01, batch size 29400, episode return 106.0M, loss 665.4\n",
      "Episode 148, epsilon   0.01, batch size 29600, episode return 181.0M, loss 182.1\n",
      "Evaluation deterministic reward 4155.1M\n",
      "Episode 149, epsilon   0.01, batch size 29800, episode return 851.3M, loss 1094.7\n",
      "Episode 150, epsilon   0.01, batch size 30000, episode return 42.7M, loss 3683.0\n",
      "Episode 151, epsilon   0.01, batch size 30200, episode return 16.0M, loss 3033.4\n",
      "Episode 152, epsilon   0.01, batch size 30400, episode return 16.2M, loss 6321.2\n",
      "Episode 153, epsilon   0.01, batch size 30600, episode return 18.8M, loss 6943.6\n",
      "Episode 154, epsilon   0.01, batch size 30800, episode return 51.4M, loss 6038.4\n",
      "Episode 155, epsilon   0.01, batch size 31000, episode return 28.5M, loss 2693.0\n",
      "Episode 156, epsilon   0.01, batch size 31200, episode return 30.9M, loss 3043.2\n",
      "Episode 157, epsilon   0.01, batch size 31400, episode return 48.9M, loss 2758.7\n",
      "Episode 158, epsilon   0.01, batch size 31600, episode return 73.7M, loss 6568.3\n",
      "Episode 159, epsilon   0.01, batch size 31800, episode return 83.1M, loss 3488.8\n",
      "Episode 160, epsilon   0.01, batch size 32000, episode return 15.0M, loss 7796.3\n",
      "Episode 161, epsilon   0.01, batch size 32200, episode return 34.8M, loss 22687.3\n",
      "Episode 162, epsilon   0.01, batch size 32400, episode return 66.6M, loss 21169.7\n",
      "Episode 163, epsilon   0.01, batch size 32600, episode return 59.9M, loss 32248.6\n",
      "Episode 164, epsilon   0.01, batch size 32800, episode return 51.7M, loss 21623.6\n",
      "Episode 165, epsilon   0.01, batch size 33000, episode return 55.1M, loss 17086.5\n",
      "Episode 166, epsilon   0.01, batch size 33200, episode return 108.4M, loss 3337.5\n",
      "Episode 167, epsilon   0.01, batch size 33400, episode return 108.4M, loss 4150.5\n",
      "Episode 168, epsilon   0.01, batch size 33600, episode return 103.9M, loss 2164.4\n",
      "Episode 169, epsilon   0.01, batch size 33800, episode return 1100.1M, loss 3545.6\n",
      "Episode 170, epsilon   0.01, batch size 34000, episode return 1228.5M, loss 1554.6\n",
      "Episode 171, epsilon   0.01, batch size 34200, episode return 114.4M, loss 4245.4\n",
      "Episode 172, epsilon   0.01, batch size 34400, episode return 117.5M, loss 6345.2\n",
      "Episode 173, epsilon   0.01, batch size 34600, episode return 1543.5M, loss 3013.8\n",
      "Episode 174, epsilon   0.01, batch size 34800, episode return 137.0M, loss 1996.5\n",
      "Episode 175, epsilon   0.01, batch size 35000, episode return 269.2M, loss 8103.7\n",
      "Evaluation deterministic reward 5437.4M\n",
      "Episode 176, epsilon   0.01, batch size 35200, episode return 155.2M, loss 3306.8\n",
      "Episode 177, epsilon   0.01, batch size 35400, episode return 128.0M, loss 719.8\n",
      "Episode 178, epsilon   0.01, batch size 35600, episode return 421.8M, loss 1071.9\n",
      "Episode 179, epsilon   0.01, batch size 35800, episode return 136.2M, loss 964.1\n",
      "Episode 180, epsilon   0.01, batch size 36000, episode return 661.5M, loss 2086.2\n",
      "Episode 181, epsilon   0.01, batch size 36200, episode return 188.6M, loss 2038.0\n",
      "Episode 182, epsilon   0.01, batch size 36400, episode return 422.0M, loss 18264.3\n",
      "Episode 183, epsilon   0.01, batch size 36600, episode return 329.6M, loss 2211.5\n",
      "Episode 184, epsilon   0.01, batch size 36800, episode return 218.9M, loss 971.6\n",
      "Episode 185, epsilon   0.01, batch size 37000, episode return 905.9M, loss 5012.4\n",
      "Episode 186, epsilon   0.01, batch size 37200, episode return 152.0M, loss 3626.2\n",
      "Episode 187, epsilon   0.01, batch size 37400, episode return 201.7M, loss 1064.4\n",
      "Episode 188, epsilon   0.01, batch size 37600, episode return 221.4M, loss 1348.4\n",
      "Episode 189, epsilon   0.01, batch size 37800, episode return 244.1M, loss 785.5\n",
      "Episode 190, epsilon   0.01, batch size 38000, episode return 898.2M, loss 469.9\n",
      "Episode 191, epsilon   0.01, batch size 38200, episode return 85.2M, loss 3519.7\n",
      "Episode 192, epsilon   0.01, batch size 38400, episode return 76.7M, loss 4165.2\n",
      "Episode 193, epsilon   0.01, batch size 38600, episode return 3507.0M, loss 1308.1\n",
      "Episode 194, epsilon   0.01, batch size 38800, episode return 627.7M, loss 969.9\n",
      "Episode 195, epsilon   0.01, batch size 39000, episode return 676.6M, loss 1325.2\n",
      "Episode 196, epsilon   0.01, batch size 39200, episode return 5915.5M, loss 1948.3\n",
      "Episode 197, epsilon   0.01, batch size 39400, episode return 975.3M, loss 614.7\n",
      "Episode 198, epsilon   0.01, batch size 39600, episode return 230.8M, loss 2336.2\n",
      "Episode 199, epsilon   0.01, batch size 39800, episode return 1219.4M, loss 1788.6\n",
      "Episode 200, epsilon   0.01, batch size 40000, episode return 79.5M, loss 2302.7\n",
      "Episode 201, epsilon   0.01, batch size 40200, episode return 235.0M, loss 1553.7\n",
      "Episode 202, epsilon   0.01, batch size 40400, episode return 256.5M, loss 3687.4\n",
      "Episode 203, epsilon   0.01, batch size 40600, episode return 40.5M, loss 7081.3\n",
      "Episode 204, epsilon   0.01, batch size 40800, episode return 1177.4M, loss 837.9\n",
      "Episode 205, epsilon   0.01, batch size 41000, episode return 273.9M, loss 416.3\n",
      "Episode 206, epsilon   0.01, batch size 41200, episode return 293.4M, loss 4491.6\n",
      "Episode 207, epsilon   0.01, batch size 41400, episode return 820.6M, loss 587.9\n",
      "Episode 208, epsilon   0.01, batch size 41600, episode return 460.3M, loss 983.9\n",
      "Episode 209, epsilon   0.01, batch size 41800, episode return 233.5M, loss 527.8\n",
      "Episode 210, epsilon   0.01, batch size 42000, episode return  1.2M, loss 506.5\n",
      "Episode 211, epsilon   0.01, batch size 42200, episode return  1.0M, loss 542.9\n",
      "Episode 212, epsilon   0.01, batch size 42400, episode return  1.1M, loss 1428.8\n",
      "Episode 213, epsilon   0.01, batch size 42600, episode return  1.8M, loss 2748.9\n",
      "Episode 214, epsilon   0.01, batch size 42800, episode return  2.6M, loss 785.5\n",
      "Episode 215, epsilon   0.01, batch size 43000, episode return 2470.8M, loss 751.7\n",
      "Episode 216, epsilon   0.01, batch size 43200, episode return  4.3M, loss 668.5\n",
      "Episode 217, epsilon   0.01, batch size 43400, episode return  1.5M, loss 600.3\n",
      "Episode 218, epsilon   0.01, batch size 43600, episode return  3.5M, loss 918.5\n",
      "Episode 219, epsilon   0.01, batch size 43800, episode return  1.3M, loss 393.5\n",
      "Episode 220, epsilon   0.01, batch size 44000, episode return  2.4M, loss 1507.7\n",
      "Episode 221, epsilon   0.01, batch size 44200, episode return  4.5M, loss 2049.9\n",
      "Episode 222, epsilon   0.01, batch size 44400, episode return 183.4M, loss 1336.8\n",
      "Episode 223, epsilon   0.01, batch size 44600, episode return 660.2M, loss 1053.8\n",
      "Episode 224, epsilon   0.01, batch size 44800, episode return  5.1M, loss 911.2\n",
      "Episode 225, epsilon   0.01, batch size 45000, episode return 295.1M, loss 564.0\n",
      "Episode 226, epsilon   0.01, batch size 45200, episode return  4.1M, loss 1134.9\n",
      "Episode 227, epsilon   0.01, batch size 45400, episode return  2.8M, loss 657.6\n",
      "Episode 228, epsilon   0.01, batch size 45600, episode return  8.0M, loss 251.1\n",
      "Episode 229, epsilon   0.01, batch size 45800, episode return  5.5M, loss 452.3\n",
      "Episode 230, epsilon   0.01, batch size 46000, episode return  3.5M, loss 477.0\n",
      "Episode 231, epsilon   0.01, batch size 46200, episode return  4.5M, loss 677.3\n",
      "Episode 232, epsilon   0.01, batch size 46400, episode return  6.2M, loss 1589.0\n",
      "Episode 233, epsilon   0.01, batch size 46600, episode return 37.0M, loss 929.2\n",
      "Episode 234, epsilon   0.01, batch size 46800, episode return 172.4M, loss 2618.0\n",
      "Episode 235, epsilon   0.01, batch size 47000, episode return 429.4M, loss 3053.8\n",
      "Episode 236, epsilon   0.01, batch size 47200, episode return 144.6M, loss 473.4\n",
      "Episode 237, epsilon   0.01, batch size 47400, episode return 901.2M, loss 807.5\n",
      "Episode 238, epsilon   0.01, batch size 47600, episode return 132.8M, loss 780.4\n",
      "Episode 239, epsilon   0.01, batch size 47800, episode return 464.9M, loss 406.9\n",
      "Episode 240, epsilon   0.01, batch size 48000, episode return 739.2M, loss 837.3\n",
      "Episode 241, epsilon   0.01, batch size 48200, episode return 313.4M, loss 382.0\n",
      "Episode 242, epsilon   0.01, batch size 48400, episode return 145.9M, loss 449.3\n",
      "Episode 243, epsilon   0.01, batch size 48600, episode return 164.3M, loss 1522.8\n",
      "Episode 244, epsilon   0.01, batch size 48800, episode return 111.6M, loss 229.4\n",
      "Episode 245, epsilon   0.01, batch size 49000, episode return  6.4M, loss 197.3\n",
      "Episode 246, epsilon   0.01, batch size 49200, episode return 649.6M, loss 559.6\n",
      "Episode 247, epsilon   0.01, batch size 49400, episode return 32.9M, loss 702.1\n",
      "Episode 248, epsilon   0.01, batch size 49600, episode return  7.2M, loss 2029.4\n",
      "Episode 249, epsilon   0.01, batch size 49800, episode return 1862.0M, loss 578.6\n",
      "Episode 250, epsilon   0.01, batch size 50000, episode return 1916.5M, loss 342.7\n",
      "Episode 251, epsilon   0.01, batch size 50200, episode return  4.3M, loss 411.9\n",
      "Episode 252, epsilon   0.01, batch size 50400, episode return  9.5M, loss 378.1\n",
      "Evaluation deterministic reward 5753.7M\n",
      "Episode 253, epsilon   0.01, batch size 50600, episode return  7.8M, loss 720.5\n",
      "Episode 254, epsilon   0.01, batch size 50800, episode return 139.7M, loss 508.4\n",
      "Episode 255, epsilon   0.01, batch size 51000, episode return 314.2M, loss 1116.7\n",
      "Episode 256, epsilon   0.01, batch size 51200, episode return 129.7M, loss 785.3\n",
      "Episode 257, epsilon   0.01, batch size 51400, episode return 2585.8M, loss 1217.8\n",
      "Episode 258, epsilon   0.01, batch size 51600, episode return  8.4M, loss 140.6\n",
      "Episode 259, epsilon   0.01, batch size 51800, episode return 364.3M, loss 536.0\n",
      "Episode 260, epsilon   0.01, batch size 52000, episode return  8.1M, loss 167.5\n",
      "Episode 261, epsilon   0.01, batch size 52200, episode return 49.3M, loss 249.0\n",
      "Episode 262, epsilon   0.01, batch size 52400, episode return  8.0M, loss 1483.8\n",
      "Episode 263, epsilon   0.01, batch size 52600, episode return 226.6M, loss 515.8\n",
      "Episode 264, epsilon   0.01, batch size 52800, episode return 622.8M, loss 441.2\n",
      "Episode 265, epsilon   0.01, batch size 53000, episode return 984.0M, loss 693.5\n",
      "Episode 266, epsilon   0.01, batch size 53200, episode return 1451.0M, loss 330.8\n",
      "Episode 267, epsilon   0.01, batch size 53400, episode return 1431.5M, loss 319.8\n",
      "Episode 268, epsilon   0.01, batch size 53600, episode return 17.2M, loss 1126.8\n",
      "Episode 269, epsilon   0.01, batch size 53800, episode return 11.4M, loss 238.3\n",
      "Episode 270, epsilon   0.01, batch size 54000, episode return  5.2M, loss 305.9\n",
      "Episode 271, epsilon   0.01, batch size 54200, episode return  8.7M, loss 278.8\n",
      "Episode 272, epsilon   0.01, batch size 54400, episode return 14.7M, loss 235.4\n",
      "Episode 273, epsilon   0.01, batch size 54600, episode return 102.8M, loss 170.7\n",
      "Episode 274, epsilon   0.01, batch size 54800, episode return 1677.4M, loss 1142.1\n",
      "Episode 275, epsilon   0.01, batch size 55000, episode return 38.9M, loss 530.8\n",
      "Episode 276, epsilon   0.01, batch size 55200, episode return 568.1M, loss 617.6\n",
      "Episode 277, epsilon   0.01, batch size 55400, episode return 1332.3M, loss 193.5\n",
      "Episode 278, epsilon   0.01, batch size 55600, episode return  5.7M, loss 2500.2\n",
      "Episode 279, epsilon   0.01, batch size 55800, episode return 15.0M, loss 160.6\n",
      "Episode 280, epsilon   0.01, batch size 56000, episode return  7.3M, loss 229.1\n",
      "Episode 281, epsilon   0.01, batch size 56200, episode return 10.3M, loss 7835.1\n",
      "Episode 282, epsilon   0.01, batch size 56400, episode return 62.1M, loss 4768.7\n",
      "Episode 283, epsilon   0.01, batch size 56600, episode return 514.4M, loss 1187.1\n",
      "Episode 284, epsilon   0.01, batch size 56800, episode return 616.9M, loss 599.8\n",
      "Episode 285, epsilon   0.01, batch size 57000, episode return 3825.2M, loss 910.3\n",
      "Episode 286, epsilon   0.01, batch size 57200, episode return 282.3M, loss 841.0\n",
      "Episode 287, epsilon   0.01, batch size 57400, episode return 42.9M, loss 312.8\n",
      "Episode 288, epsilon   0.01, batch size 57600, episode return 310.4M, loss 279.2\n",
      "Episode 289, epsilon   0.01, batch size 57800, episode return 69.1M, loss 1751.7\n",
      "Episode 290, epsilon   0.01, batch size 58000, episode return 2707.3M, loss 1736.3\n",
      "Episode 291, epsilon   0.01, batch size 58200, episode return 14.7M, loss 373.2\n",
      "Episode 292, epsilon   0.01, batch size 58400, episode return 221.3M, loss 308.1\n",
      "Episode 293, epsilon   0.01, batch size 58600, episode return 558.0M, loss 189.4\n",
      "Episode 294, epsilon   0.01, batch size 58800, episode return 817.2M, loss 210.8\n",
      "Episode 295, epsilon   0.01, batch size 59000, episode return 32.3M, loss 161.2\n",
      "Episode 296, epsilon   0.01, batch size 59200, episode return 358.8M, loss 216.3\n",
      "Episode 297, epsilon   0.01, batch size 59400, episode return 714.2M, loss 438.4\n",
      "Episode 298, epsilon   0.01, batch size 59600, episode return 707.5M, loss 215.0\n",
      "Episode 299, epsilon   0.01, batch size 59800, episode return  6.6M, loss 286.0\n",
      "Episode 300, epsilon   0.01, batch size 60000, episode return 12.2M, loss 240.6\n"
     ]
    }
   ],
   "source": [
    "env = TimeLimit(HIVPatient(), max_episode_steps=200)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Declare network\n",
    "state_dim = env.observation_space.shape[0]\n",
    "n_action = env.action_space.n \n",
    "nb_neurons=128\n",
    "DQN = torch.nn.Sequential(nn.Linear(state_dim, nb_neurons),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(nb_neurons, nb_neurons),\n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(nb_neurons, n_action)).to(device)\n",
    "\n",
    "# DQN config\n",
    "config = {'nb_actions': n_action, 'learning_rate': 0.01,\n",
    "          'gamma': 0.95, 'buffer_size': 100_000,\n",
    "          'epsilon_min': 0.01, 'epsilon_max': 1.,\n",
    "          'epsilon_decay_period': 5_000, 'epsilon_delay_decay': 600,\n",
    "          'batch_size': 32, 'model_path': 'best_model_standard_scaling.pth',\n",
    "          'scaling': 'standard', 'criterion': torch.nn.SmoothL1Loss()}\n",
    "\n",
    "# Train agent\n",
    "agent = dqn_agent(config, DQN)\n",
    "scores = agent.train(env, 300)\n",
    "#plt.plot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with deterministic reward 5819.66M\n",
      "Episode   1, epsilon   0.96, batch size   200, episode return 10.6M, loss 21571418.0\n",
      "Episode   2, epsilon   0.92, batch size   400, episode return  7.9M, loss 1540596.8\n",
      "Episode   3, epsilon   0.88, batch size   600, episode return 12.2M, loss 287791.9\n",
      "Episode   4, epsilon   0.84, batch size   800, episode return  6.9M, loss 128160.9\n",
      "Episode   5, epsilon   0.80, batch size  1000, episode return 13.0M, loss 120558.4\n",
      "Episode   6, epsilon   0.76, batch size  1200, episode return  9.3M, loss 62426.2\n",
      "Episode   7, epsilon   0.72, batch size  1400, episode return  9.8M, loss 55130.7\n",
      "Episode   8, epsilon   0.68, batch size  1600, episode return 11.9M, loss 37057.6\n",
      "Episode   9, epsilon   0.64, batch size  1800, episode return  9.2M, loss 34196.6\n",
      "Episode  10, epsilon   0.60, batch size  2000, episode return  8.1M, loss 28444.3\n",
      "Episode  11, epsilon   0.56, batch size  2200, episode return  8.7M, loss 19986.3\n",
      "Episode  12, epsilon   0.53, batch size  2400, episode return 12.3M, loss 22393.5\n",
      "Episode  13, epsilon   0.49, batch size  2600, episode return  9.6M, loss 8891.2\n",
      "Episode  14, epsilon   0.45, batch size  2800, episode return 15.6M, loss 30459.7\n",
      "Episode  15, epsilon   0.41, batch size  3000, episode return  6.8M, loss 10005.7\n",
      "Episode  16, epsilon   0.37, batch size  3200, episode return 14.6M, loss 11118.4\n",
      "Episode  17, epsilon   0.33, batch size  3400, episode return  7.4M, loss 15167.2\n",
      "Episode  18, epsilon   0.29, batch size  3600, episode return  6.3M, loss 31949.9\n",
      "Episode  19, epsilon   0.25, batch size  3800, episode return  8.6M, loss 81098.1\n",
      "Episode  20, epsilon   0.21, batch size  4000, episode return  6.2M, loss 37656.2\n",
      "Episode  21, epsilon   0.17, batch size  4200, episode return  9.9M, loss 105026.2\n",
      "Episode  22, epsilon   0.13, batch size  4400, episode return  3.1M, loss 131202136.0\n",
      "Episode  23, epsilon   0.09, batch size  4600, episode return 15.5M, loss 5188416.0\n",
      "Episode  24, epsilon   0.05, batch size  4800, episode return  8.7M, loss 3521627.0\n",
      "Episode  25, epsilon   0.01, batch size  5000, episode return  5.4M, loss 765074.1\n",
      "Episode  26, epsilon   0.01, batch size  5200, episode return  8.7M, loss 389835.8\n",
      "Episode  27, epsilon   0.01, batch size  5400, episode return  6.9M, loss 326687.5\n",
      "Episode  28, epsilon   0.01, batch size  5600, episode return  9.1M, loss 533623.7\n",
      "Episode  29, epsilon   0.01, batch size  5800, episode return  4.6M, loss 107784.8\n",
      "Episode  30, epsilon   0.01, batch size  6000, episode return  4.6M, loss 281609.4\n",
      "Episode  31, epsilon   0.01, batch size  6200, episode return 10.0M, loss 261228.2\n",
      "Episode  32, epsilon   0.01, batch size  6400, episode return 12.7M, loss 68165.9\n",
      "Episode  33, epsilon   0.01, batch size  6600, episode return 20.1M, loss 143027.7\n",
      "Episode  34, epsilon   0.01, batch size  6800, episode return  9.1M, loss 62295.9\n",
      "Episode  35, epsilon   0.01, batch size  7000, episode return 14.0M, loss 186460.2\n",
      "Episode  36, epsilon   0.01, batch size  7200, episode return 36.4M, loss 40945.4\n",
      "Episode  37, epsilon   0.01, batch size  7400, episode return 28.8M, loss 69443.0\n",
      "Episode  38, epsilon   0.01, batch size  7600, episode return 11.2M, loss 64648.6\n",
      "Episode  39, epsilon   0.01, batch size  7800, episode return 29.6M, loss 57443.4\n",
      "Episode  40, epsilon   0.01, batch size  8000, episode return 10.7M, loss 21786.4\n",
      "Episode  41, epsilon   0.01, batch size  8200, episode return  9.0M, loss 147571.4\n",
      "Episode  42, epsilon   0.01, batch size  8400, episode return 12.7M, loss 81126.2\n",
      "Episode  43, epsilon   0.01, batch size  8600, episode return  7.0M, loss 45780.8\n",
      "Episode  44, epsilon   0.01, batch size  8800, episode return 38.6M, loss 26431.5\n",
      "Episode  45, epsilon   0.01, batch size  9000, episode return 31.0M, loss 48537.5\n",
      "Episode  46, epsilon   0.01, batch size  9200, episode return  5.9M, loss 195088.6\n",
      "Episode  47, epsilon   0.01, batch size  9400, episode return  3.3M, loss 40339.9\n",
      "Episode  48, epsilon   0.01, batch size  9600, episode return  5.2M, loss 21078.7\n",
      "Episode  49, epsilon   0.01, batch size  9800, episode return  5.1M, loss 25201.2\n",
      "Episode  50, epsilon   0.01, batch size 10000, episode return  7.2M, loss 11522.0\n",
      "Episode  51, epsilon   0.01, batch size 10200, episode return  4.2M, loss 27370.5\n",
      "Episode  52, epsilon   0.01, batch size 10400, episode return  7.1M, loss 14257.4\n",
      "Episode  53, epsilon   0.01, batch size 10600, episode return  3.3M, loss 110506.3\n",
      "Episode  54, epsilon   0.01, batch size 10800, episode return  5.5M, loss 1359038.8\n",
      "Episode  55, epsilon   0.01, batch size 11000, episode return  8.2M, loss 164332.4\n",
      "Episode  56, epsilon   0.01, batch size 11200, episode return 10.6M, loss 33427.3\n",
      "Episode  57, epsilon   0.01, batch size 11400, episode return  7.2M, loss 5997.4\n",
      "Episode  58, epsilon   0.01, batch size 11600, episode return 33.5M, loss 11417.0\n",
      "Episode  59, epsilon   0.01, batch size 11800, episode return 50.0M, loss 6760.8\n",
      "Episode  60, epsilon   0.01, batch size 12000, episode return 11.0M, loss 18769.6\n",
      "Episode  61, epsilon   0.01, batch size 12200, episode return  7.5M, loss 30371.0\n",
      "Episode  62, epsilon   0.01, batch size 12400, episode return 12.5M, loss 16339.2\n",
      "Episode  63, epsilon   0.01, batch size 12600, episode return  9.3M, loss 80508.5\n",
      "Episode  64, epsilon   0.01, batch size 12800, episode return 11.7M, loss 1030852.8\n",
      "Episode  65, epsilon   0.01, batch size 13000, episode return 14.4M, loss 27959.3\n",
      "Episode  66, epsilon   0.01, batch size 13200, episode return 30.7M, loss 20573.7\n",
      "Episode  67, epsilon   0.01, batch size 13400, episode return 15.1M, loss 25514.1\n",
      "Episode  68, epsilon   0.01, batch size 13600, episode return  9.9M, loss 29827.2\n",
      "Episode  69, epsilon   0.01, batch size 13800, episode return  7.3M, loss 6201.3\n",
      "Episode  70, epsilon   0.01, batch size 14000, episode return 25.6M, loss 108140.3\n",
      "Episode  71, epsilon   0.01, batch size 14200, episode return  7.0M, loss 18050.4\n",
      "Episode  72, epsilon   0.01, batch size 14400, episode return  7.7M, loss 3900.6\n",
      "Episode  73, epsilon   0.01, batch size 14600, episode return  6.6M, loss 35796.1\n",
      "Episode  74, epsilon   0.01, batch size 14800, episode return  6.2M, loss 19847.4\n",
      "Episode  75, epsilon   0.01, batch size 15000, episode return 11.3M, loss 77431.3\n",
      "Episode  76, epsilon   0.01, batch size 15200, episode return 38.4M, loss 35319.2\n",
      "Episode  77, epsilon   0.01, batch size 15400, episode return 32.1M, loss 6689.6\n",
      "Episode  78, epsilon   0.01, batch size 15600, episode return 69.2M, loss 4019.9\n",
      "Episode  79, epsilon   0.01, batch size 15800, episode return 65.9M, loss 2737.2\n",
      "Episode  80, epsilon   0.01, batch size 16000, episode return 39.0M, loss 3662.0\n",
      "Episode  81, epsilon   0.01, batch size 16200, episode return 23.8M, loss 6168.4\n",
      "Episode  82, epsilon   0.01, batch size 16400, episode return 80.8M, loss 9794.2\n",
      "Episode  83, epsilon   0.01, batch size 16600, episode return 11.5M, loss 12646.8\n",
      "Episode  84, epsilon   0.01, batch size 16800, episode return 22.1M, loss 15825.7\n",
      "Episode  85, epsilon   0.01, batch size 17000, episode return 14.5M, loss 6373.8\n",
      "Episode  86, epsilon   0.01, batch size 17200, episode return 10.6M, loss 6912.0\n",
      "Episode  87, epsilon   0.01, batch size 17400, episode return 24.5M, loss 4848.3\n",
      "Episode  88, epsilon   0.01, batch size 17600, episode return  5.1M, loss 2028.2\n",
      "Episode  89, epsilon   0.01, batch size 17800, episode return 31.2M, loss 9656.1\n",
      "Episode  90, epsilon   0.01, batch size 18000, episode return 10.5M, loss 23104.3\n",
      "Episode  91, epsilon   0.01, batch size 18200, episode return  7.2M, loss 8501.8\n",
      "Episode  92, epsilon   0.01, batch size 18400, episode return  6.8M, loss 4141.5\n",
      "Episode  93, epsilon   0.01, batch size 18600, episode return  9.6M, loss 4018.7\n",
      "Episode  94, epsilon   0.01, batch size 18800, episode return 11.2M, loss 2214.8\n",
      "Episode  95, epsilon   0.01, batch size 19000, episode return 27.3M, loss 2600.9\n",
      "Episode  96, epsilon   0.01, batch size 19200, episode return 21.6M, loss 497.5\n",
      "Episode  97, epsilon   0.01, batch size 19400, episode return 16.2M, loss 495.0\n",
      "Episode  98, epsilon   0.01, batch size 19600, episode return 20.6M, loss 2604.3\n",
      "Episode  99, epsilon   0.01, batch size 19800, episode return 52.4M, loss 745.1\n",
      "Episode 100, epsilon   0.01, batch size 20000, episode return 15.9M, loss 1123.3\n",
      "Episode 101, epsilon   0.01, batch size 20200, episode return 19.1M, loss 13042.6\n",
      "Episode 102, epsilon   0.01, batch size 20400, episode return  5.6M, loss 12594.5\n",
      "Episode 103, epsilon   0.01, batch size 20600, episode return  4.0M, loss 2030.0\n",
      "Episode 104, epsilon   0.01, batch size 20800, episode return  5.7M, loss 898.1\n",
      "Episode 105, epsilon   0.01, batch size 21000, episode return  4.7M, loss 486.9\n",
      "Episode 106, epsilon   0.01, batch size 21200, episode return  9.1M, loss 1089.2\n",
      "Episode 107, epsilon   0.01, batch size 21400, episode return  9.6M, loss 409.6\n",
      "Episode 108, epsilon   0.01, batch size 21600, episode return 23.1M, loss 4469.2\n",
      "Episode 109, epsilon   0.01, batch size 21800, episode return  3.8M, loss 1872.0\n",
      "Episode 110, epsilon   0.01, batch size 22000, episode return  5.6M, loss 4337.3\n",
      "Episode 111, epsilon   0.01, batch size 22200, episode return  5.4M, loss 4600.4\n",
      "Episode 112, epsilon   0.01, batch size 22400, episode return  5.9M, loss 10289.2\n",
      "Episode 113, epsilon   0.01, batch size 22600, episode return  7.7M, loss 1164.1\n",
      "Episode 114, epsilon   0.01, batch size 22800, episode return 36.8M, loss 486.4\n",
      "Episode 115, epsilon   0.01, batch size 23000, episode return 10.8M, loss 447.7\n",
      "Episode 116, epsilon   0.01, batch size 23200, episode return 10.8M, loss 640.0\n",
      "Episode 117, epsilon   0.01, batch size 23400, episode return  4.8M, loss 4377389.0\n",
      "Episode 118, epsilon   0.01, batch size 23600, episode return 50.3M, loss 309669.1\n",
      "Episode 119, epsilon   0.01, batch size 23800, episode return 94.1M, loss 286487.7\n",
      "Episode 120, epsilon   0.01, batch size 24000, episode return 50.8M, loss 86663.1\n",
      "Episode 121, epsilon   0.01, batch size 24200, episode return 205.3M, loss 49798.2\n",
      "Episode 122, epsilon   0.01, batch size 24400, episode return 1326.9M, loss 463868.2\n",
      "Episode 123, epsilon   0.01, batch size 24600, episode return  8.8M, loss 15934920.0\n",
      "Episode 124, epsilon   0.01, batch size 24800, episode return  7.9M, loss 1431028.8\n",
      "Episode 125, epsilon   0.01, batch size 25000, episode return  5.8M, loss 1548917.5\n",
      "Episode 126, epsilon   0.01, batch size 25200, episode return  6.1M, loss 966019.6\n",
      "Episode 127, epsilon   0.01, batch size 25400, episode return  8.8M, loss 136342784.0\n",
      "Episode 128, epsilon   0.01, batch size 25600, episode return 12.9M, loss 2436114944.0\n",
      "Episode 129, epsilon   0.01, batch size 25800, episode return 22.3M, loss 1474295.5\n",
      "Episode 130, epsilon   0.01, batch size 26000, episode return 15.8M, loss 147762112.0\n",
      "Episode 131, epsilon   0.01, batch size 26200, episode return 29.3M, loss 14178667.0\n",
      "Episode 132, epsilon   0.01, batch size 26400, episode return  9.0M, loss 14078641.0\n",
      "Episode 133, epsilon   0.01, batch size 26600, episode return 11.5M, loss 73839712.0\n",
      "Episode 134, epsilon   0.01, batch size 26800, episode return 32.5M, loss 231165280.0\n",
      "Episode 135, epsilon   0.01, batch size 27000, episode return 33.2M, loss 173578624.0\n",
      "Episode 136, epsilon   0.01, batch size 27200, episode return 34.2M, loss 43680272.0\n",
      "Episode 137, epsilon   0.01, batch size 27400, episode return 76.1M, loss 67541712.0\n",
      "Episode 138, epsilon   0.01, batch size 27600, episode return 90.2M, loss 68454168.0\n",
      "Episode 139, epsilon   0.01, batch size 27800, episode return 74.4M, loss 30487500.0\n",
      "Episode 140, epsilon   0.01, batch size 28000, episode return 171.0M, loss 7632627.0\n",
      "Episode 141, epsilon   0.01, batch size 28200, episode return 135.2M, loss 23413282.0\n",
      "Episode 142, epsilon   0.01, batch size 28400, episode return 45.4M, loss 4955002.0\n",
      "Episode 143, epsilon   0.01, batch size 28600, episode return 165.7M, loss 27127668.0\n",
      "Episode 144, epsilon   0.01, batch size 28800, episode return 158.5M, loss 2643078.0\n",
      "Episode 145, epsilon   0.01, batch size 29000, episode return 361.3M, loss 6669662.5\n",
      "Episode 146, epsilon   0.01, batch size 29200, episode return 50.7M, loss 1988678656.0\n",
      "Episode 147, epsilon   0.01, batch size 29400, episode return 139.7M, loss 12011248.0\n",
      "Episode 148, epsilon   0.01, batch size 29600, episode return 191.3M, loss 5338720.5\n",
      "Episode 149, epsilon   0.01, batch size 29800, episode return 153.6M, loss 13572971.0\n",
      "Episode 150, epsilon   0.01, batch size 30000, episode return 124.7M, loss 40886064.0\n",
      "Episode 151, epsilon   0.01, batch size 30200, episode return 224.1M, loss 2784716.8\n",
      "Episode 152, epsilon   0.01, batch size 30400, episode return 209.5M, loss 3852686.2\n",
      "Episode 153, epsilon   0.01, batch size 30600, episode return 260.7M, loss 6586085.0\n",
      "Episode 154, epsilon   0.01, batch size 30800, episode return 281.2M, loss 11225361.0\n",
      "Episode 155, epsilon   0.01, batch size 31000, episode return 226.4M, loss 3096839.5\n",
      "Episode 156, epsilon   0.01, batch size 31200, episode return 80.7M, loss 5782299.0\n",
      "Episode 157, epsilon   0.01, batch size 31400, episode return 169.1M, loss 9294862.0\n",
      "Episode 158, epsilon   0.01, batch size 31600, episode return 131.8M, loss 15586613.0\n",
      "Episode 159, epsilon   0.01, batch size 31800, episode return 176.9M, loss 12152291.0\n",
      "Episode 160, epsilon   0.01, batch size 32000, episode return 130.9M, loss 3860669.0\n",
      "Episode 161, epsilon   0.01, batch size 32200, episode return 126.7M, loss 1855256.2\n",
      "Episode 162, epsilon   0.01, batch size 32400, episode return 50.7M, loss 2411233.5\n",
      "Episode 163, epsilon   0.01, batch size 32600, episode return 125.5M, loss 1224453.0\n",
      "Episode 164, epsilon   0.01, batch size 32800, episode return 209.9M, loss 606640.7\n",
      "Episode 165, epsilon   0.01, batch size 33000, episode return 156.4M, loss 3798352.0\n",
      "Episode 166, epsilon   0.01, batch size 33200, episode return 171.1M, loss 777670.4\n",
      "Episode 167, epsilon   0.01, batch size 33400, episode return 2446.3M, loss 1541052.4\n",
      "Episode 168, epsilon   0.01, batch size 33600, episode return 115.6M, loss 10597541.0\n",
      "Episode 169, epsilon   0.01, batch size 33800, episode return 57.1M, loss 477391968.0\n",
      "Episode 170, epsilon   0.01, batch size 34000, episode return 13.4M, loss 217380864.0\n",
      "Episode 171, epsilon   0.01, batch size 34200, episode return 136.4M, loss 74062000.0\n",
      "Episode 172, epsilon   0.01, batch size 34400, episode return 150.2M, loss 17775254.0\n",
      "Episode 173, epsilon   0.01, batch size 34600, episode return 148.8M, loss 6050015.5\n",
      "Episode 174, epsilon   0.01, batch size 34800, episode return 169.5M, loss 5671446.0\n",
      "Episode 175, epsilon   0.01, batch size 35000, episode return 263.5M, loss 4647421.0\n",
      "Episode 176, epsilon   0.01, batch size 35200, episode return 421.7M, loss 5739446.5\n",
      "Episode 177, epsilon   0.01, batch size 35400, episode return  9.4M, loss 4127141.0\n",
      "Episode 178, epsilon   0.01, batch size 35600, episode return 329.9M, loss 1339411.8\n",
      "Episode 179, epsilon   0.01, batch size 35800, episode return 968.1M, loss 3245239.5\n",
      "Episode 180, epsilon   0.01, batch size 36000, episode return  3.7M, loss 1118183.2\n",
      "Episode 181, epsilon   0.01, batch size 36200, episode return  7.0M, loss 3352172.0\n",
      "Episode 182, epsilon   0.01, batch size 36400, episode return 10.8M, loss 2813643.0\n",
      "Episode 183, epsilon   0.01, batch size 36600, episode return  5.5M, loss 3649903.5\n",
      "Episode 184, epsilon   0.01, batch size 36800, episode return  7.6M, loss 4277254.0\n",
      "Episode 185, epsilon   0.01, batch size 37000, episode return  8.3M, loss 1248913.2\n",
      "Episode 186, epsilon   0.01, batch size 37200, episode return  4.6M, loss 1344448.8\n",
      "Episode 187, epsilon   0.01, batch size 37400, episode return  6.0M, loss 2774479.0\n",
      "Episode 188, epsilon   0.01, batch size 37600, episode return  8.6M, loss 1585367.5\n",
      "Episode 189, epsilon   0.01, batch size 37800, episode return  7.7M, loss 34797368.0\n",
      "Episode 190, epsilon   0.01, batch size 38000, episode return 13.7M, loss 1082976.9\n",
      "Episode 191, epsilon   0.01, batch size 38200, episode return 11.6M, loss 15031444.0\n",
      "Episode 192, epsilon   0.01, batch size 38400, episode return 10.1M, loss 1810839.8\n",
      "Episode 193, epsilon   0.01, batch size 38600, episode return 16.0M, loss 1984922.4\n",
      "Episode 194, epsilon   0.01, batch size 38800, episode return 3823.8M, loss 1024310.0\n",
      "Episode 195, epsilon   0.01, batch size 39000, episode return 12.3M, loss 8282231.5\n",
      "Episode 196, epsilon   0.01, batch size 39200, episode return  5.5M, loss 89873088.0\n",
      "Episode 197, epsilon   0.01, batch size 39400, episode return  3.2M, loss 197625376.0\n",
      "Episode 198, epsilon   0.01, batch size 39600, episode return  2.5M, loss 52563444.0\n",
      "Episode 199, epsilon   0.01, batch size 39800, episode return  4.4M, loss 17399228.0\n",
      "Episode 200, epsilon   0.01, batch size 40000, episode return 11.7M, loss 5246856.0\n",
      "Episode 201, epsilon   0.01, batch size 40200, episode return 945.5M, loss 8884852.0\n",
      "Episode 202, epsilon   0.01, batch size 40400, episode return 17.8M, loss 5559099.0\n",
      "Episode 203, epsilon   0.01, batch size 40600, episode return 15.4M, loss 6409240.0\n",
      "Episode 204, epsilon   0.01, batch size 40800, episode return 14.4M, loss 5393938.0\n",
      "Episode 205, epsilon   0.01, batch size 41000, episode return 17.6M, loss 2029046.5\n",
      "Episode 206, epsilon   0.01, batch size 41200, episode return 15.5M, loss 2122070.0\n",
      "Episode 207, epsilon   0.01, batch size 41400, episode return 26.3M, loss 867160.0\n",
      "Episode 208, epsilon   0.01, batch size 41600, episode return 14.2M, loss 2519339.5\n",
      "Episode 209, epsilon   0.01, batch size 41800, episode return 15.6M, loss 896197.1\n",
      "Episode 210, epsilon   0.01, batch size 42000, episode return 14.1M, loss 3173209.8\n",
      "Episode 211, epsilon   0.01, batch size 42200, episode return 18.1M, loss 1381512.1\n",
      "Episode 212, epsilon   0.01, batch size 42400, episode return 10.2M, loss 2477196.2\n",
      "Episode 213, epsilon   0.01, batch size 42600, episode return  7.1M, loss 8424089.0\n",
      "Episode 214, epsilon   0.01, batch size 42800, episode return 14.0M, loss 1446035.0\n",
      "Episode 215, epsilon   0.01, batch size 43000, episode return  9.3M, loss 6927134.5\n",
      "Episode 216, epsilon   0.01, batch size 43200, episode return  7.1M, loss 9192386.0\n",
      "Episode 217, epsilon   0.01, batch size 43400, episode return  9.1M, loss 54309924.0\n",
      "Episode 218, epsilon   0.01, batch size 43600, episode return  3.6M, loss 13346412.0\n",
      "Episode 219, epsilon   0.01, batch size 43800, episode return 13.1M, loss 2999451.5\n",
      "Episode 220, epsilon   0.01, batch size 44000, episode return 209.8M, loss 649550.9\n",
      "Episode 221, epsilon   0.01, batch size 44200, episode return 160.8M, loss 6334021.5\n",
      "Episode 222, epsilon   0.01, batch size 44400, episode return 13.4M, loss 51924228.0\n",
      "Episode 223, epsilon   0.01, batch size 44600, episode return 348.4M, loss 3579625.8\n",
      "Episode 224, epsilon   0.01, batch size 44800, episode return 36.3M, loss 3634659.0\n",
      "Episode 225, epsilon   0.01, batch size 45000, episode return 24.5M, loss 1310154.0\n",
      "Episode 226, epsilon   0.01, batch size 45200, episode return 138.5M, loss 4900228.5\n",
      "Episode 227, epsilon   0.01, batch size 45400, episode return 12.5M, loss 48193576.0\n",
      "Episode 228, epsilon   0.01, batch size 45600, episode return  4.3M, loss 2982362.2\n",
      "Episode 229, epsilon   0.01, batch size 45800, episode return 11.3M, loss 1094698.5\n",
      "Episode 230, epsilon   0.01, batch size 46000, episode return 18.1M, loss 2346079.2\n",
      "Episode 231, epsilon   0.01, batch size 46200, episode return 10.8M, loss 765398.1\n",
      "Episode 232, epsilon   0.01, batch size 46400, episode return  9.1M, loss 1142635.1\n",
      "Episode 233, epsilon   0.01, batch size 46600, episode return 10.4M, loss 442357.6\n",
      "Episode 234, epsilon   0.01, batch size 46800, episode return  5.2M, loss 576572.2\n",
      "Episode 235, epsilon   0.01, batch size 47000, episode return  5.1M, loss 2173877.5\n",
      "Episode 236, epsilon   0.01, batch size 47200, episode return  5.5M, loss 748616.1\n",
      "Episode 237, epsilon   0.01, batch size 47400, episode return  4.7M, loss 478447.2\n",
      "Episode 238, epsilon   0.01, batch size 47600, episode return  6.3M, loss 692034.1\n",
      "Episode 239, epsilon   0.01, batch size 47800, episode return  4.7M, loss 339591.8\n",
      "Episode 240, epsilon   0.01, batch size 48000, episode return  4.2M, loss 951097.1\n",
      "Episode 241, epsilon   0.01, batch size 48200, episode return 55.3M, loss 704956.7\n",
      "Episode 242, epsilon   0.01, batch size 48400, episode return 50.6M, loss 606377.2\n",
      "Episode 243, epsilon   0.01, batch size 48600, episode return 51.2M, loss 357376.0\n",
      "Episode 244, epsilon   0.01, batch size 48800, episode return 61.7M, loss 320946.3\n",
      "Episode 245, epsilon   0.01, batch size 49000, episode return 63.4M, loss 412829.2\n",
      "Episode 246, epsilon   0.01, batch size 49200, episode return 62.1M, loss 1276015.6\n",
      "Episode 247, epsilon   0.01, batch size 49400, episode return 360.1M, loss 462160.6\n",
      "Episode 248, epsilon   0.01, batch size 49600, episode return 113.2M, loss 438274.0\n",
      "Episode 249, epsilon   0.01, batch size 49800, episode return 82.7M, loss 2027992.6\n",
      "Episode 250, epsilon   0.01, batch size 50000, episode return  8.5M, loss 33430438.0\n",
      "Episode 251, epsilon   0.01, batch size 50200, episode return  3.2M, loss 3337179.8\n",
      "Episode 252, epsilon   0.01, batch size 50400, episode return 27.4M, loss 2540377.5\n",
      "Episode 253, epsilon   0.01, batch size 50600, episode return 236.7M, loss 547881.6\n",
      "Episode 254, epsilon   0.01, batch size 50800, episode return 264.7M, loss 2220700.2\n",
      "Episode 255, epsilon   0.01, batch size 51000, episode return 280.4M, loss 859948.9\n",
      "Episode 256, epsilon   0.01, batch size 51200, episode return 206.8M, loss 694128.9\n",
      "Episode 257, epsilon   0.01, batch size 51400, episode return 174.2M, loss 450381.2\n",
      "Episode 258, epsilon   0.01, batch size 51600, episode return 13.0M, loss 578577.4\n",
      "Episode 259, epsilon   0.01, batch size 51800, episode return 188.0M, loss 356451.9\n",
      "Episode 260, epsilon   0.01, batch size 52000, episode return 19.0M, loss 261109.7\n",
      "Episode 261, epsilon   0.01, batch size 52200, episode return 253.0M, loss 1072294.0\n",
      "Episode 262, epsilon   0.01, batch size 52400, episode return  4.9M, loss 813367.6\n",
      "Episode 263, epsilon   0.01, batch size 52600, episode return 11.5M, loss 1430888.4\n",
      "Episode 264, epsilon   0.01, batch size 52800, episode return 336.1M, loss 1029121.6\n",
      "Episode 265, epsilon   0.01, batch size 53000, episode return 2316.5M, loss 280457.2\n",
      "Episode 266, epsilon   0.01, batch size 53200, episode return 50.3M, loss 2062662.1\n",
      "Episode 267, epsilon   0.01, batch size 53400, episode return 11.3M, loss 655156.9\n",
      "Episode 268, epsilon   0.01, batch size 53600, episode return 202.0M, loss 728563.8\n",
      "Episode 269, epsilon   0.01, batch size 53800, episode return 16.1M, loss 1139401.0\n",
      "Episode 270, epsilon   0.01, batch size 54000, episode return 86.7M, loss 283210.8\n",
      "Episode 271, epsilon   0.01, batch size 54200, episode return 13.0M, loss 285089.3\n",
      "Episode 272, epsilon   0.01, batch size 54400, episode return  7.2M, loss 113816.7\n",
      "Episode 273, epsilon   0.01, batch size 54600, episode return  7.0M, loss 525299.6\n",
      "Episode 274, epsilon   0.01, batch size 54800, episode return  9.9M, loss 597048.5\n",
      "Episode 275, epsilon   0.01, batch size 55000, episode return 33.8M, loss 15714643.0\n",
      "Episode 276, epsilon   0.01, batch size 55200, episode return 109.1M, loss 21636904.0\n",
      "Episode 277, epsilon   0.01, batch size 55400, episode return 49.3M, loss 863893.9\n",
      "Episode 278, epsilon   0.01, batch size 55600, episode return 131.6M, loss 2079216.8\n",
      "Episode 279, epsilon   0.01, batch size 55800, episode return 11.7M, loss 2163857.8\n",
      "Episode 280, epsilon   0.01, batch size 56000, episode return  3.7M, loss 3614152.0\n",
      "Episode 281, epsilon   0.01, batch size 56200, episode return  6.7M, loss 1999020672.0\n",
      "Episode 282, epsilon   0.01, batch size 56400, episode return 71.3M, loss 8817022.0\n",
      "Episode 283, epsilon   0.01, batch size 56600, episode return 43.6M, loss 74427536.0\n",
      "Episode 284, epsilon   0.01, batch size 56800, episode return 371.4M, loss 7220430.0\n",
      "Episode 285, epsilon   0.01, batch size 57000, episode return  8.4M, loss 18972438.0\n",
      "Episode 286, epsilon   0.01, batch size 57200, episode return 21.8M, loss 4829423.0\n",
      "Episode 287, epsilon   0.01, batch size 57400, episode return 1383.1M, loss 1349294.8\n",
      "Episode 288, epsilon   0.01, batch size 57600, episode return 12.0M, loss 6117755.5\n",
      "Episode 289, epsilon   0.01, batch size 57800, episode return  4.5M, loss 3366618.5\n",
      "Episode 290, epsilon   0.01, batch size 58000, episode return  7.6M, loss 943477.1\n",
      "Episode 291, epsilon   0.01, batch size 58200, episode return 11.7M, loss 233154.6\n",
      "Episode 292, epsilon   0.01, batch size 58400, episode return 855.7M, loss 2562820.2\n",
      "Episode 293, epsilon   0.01, batch size 58600, episode return 454.4M, loss 1237008.8\n",
      "Episode 294, epsilon   0.01, batch size 58800, episode return 244.7M, loss 865029.3\n",
      "Episode 295, epsilon   0.01, batch size 59000, episode return 16.2M, loss 54127160.0\n",
      "Episode 296, epsilon   0.01, batch size 59200, episode return 1063.4M, loss 7005317.0\n",
      "Evaluation deterministic reward 6123.1M\n",
      "Episode 297, epsilon   0.01, batch size 59400, episode return 1437.0M, loss 371421.9\n",
      "Episode 298, epsilon   0.01, batch size 59600, episode return 61.1M, loss 15395754.0\n",
      "Episode 299, epsilon   0.01, batch size 59800, episode return 78.7M, loss 217495072.0\n",
      "Episode 300, epsilon   0.01, batch size 60000, episode return  4.5M, loss 12190222.0\n",
      "Episode 301, epsilon   0.01, batch size 60200, episode return 114.3M, loss 7034640.5\n",
      "Episode 302, epsilon   0.01, batch size 60400, episode return 2118.0M, loss 5316695.0\n",
      "Episode 303, epsilon   0.01, batch size 60600, episode return 316.5M, loss 3249658.2\n",
      "Episode 304, epsilon   0.01, batch size 60800, episode return 203.4M, loss 7077031.0\n",
      "Episode 305, epsilon   0.01, batch size 61000, episode return 2148.2M, loss 1932575.6\n",
      "Episode 306, epsilon   0.01, batch size 61200, episode return 14.2M, loss 1468326.8\n",
      "Episode 307, epsilon   0.01, batch size 61400, episode return 953.9M, loss 2116927.5\n",
      "Episode 308, epsilon   0.01, batch size 61600, episode return 988.5M, loss 761344.9\n",
      "Episode 309, epsilon   0.01, batch size 61800, episode return 1787.8M, loss 657479.7\n",
      "Episode 310, epsilon   0.01, batch size 62000, episode return 2134.6M, loss 727321.5\n",
      "Episode 311, epsilon   0.01, batch size 62200, episode return 2685.1M, loss 1183745.1\n",
      "Episode 312, epsilon   0.01, batch size 62400, episode return 3067.2M, loss 784606.1\n",
      "Episode 313, epsilon   0.01, batch size 62600, episode return 1396.9M, loss 1358505.5\n",
      "Episode 314, epsilon   0.01, batch size 62800, episode return 912.3M, loss 3734908.2\n",
      "Episode 315, epsilon   0.01, batch size 63000, episode return 952.5M, loss 1988773.1\n",
      "Episode 316, epsilon   0.01, batch size 63200, episode return 2073.0M, loss 2027796.4\n",
      "Episode 317, epsilon   0.01, batch size 63400, episode return 279.8M, loss 2350424.5\n",
      "Episode 318, epsilon   0.01, batch size 63600, episode return 19.0M, loss 162140608.0\n",
      "Episode 319, epsilon   0.01, batch size 63800, episode return 49.8M, loss 5488001.0\n",
      "Episode 320, epsilon   0.01, batch size 64000, episode return 108.0M, loss 4597016.0\n",
      "Episode 321, epsilon   0.01, batch size 64200, episode return 68.6M, loss 16230235.0\n",
      "Episode 322, epsilon   0.01, batch size 64400, episode return 85.2M, loss 1457342.0\n",
      "Episode 323, epsilon   0.01, batch size 64600, episode return 38.7M, loss 1392125.5\n",
      "Episode 324, epsilon   0.01, batch size 64800, episode return 40.9M, loss 3189056.5\n",
      "Episode 325, epsilon   0.01, batch size 65000, episode return 28.3M, loss 1812482.5\n",
      "Episode 326, epsilon   0.01, batch size 65200, episode return 68.6M, loss 1395184.5\n",
      "Episode 327, epsilon   0.01, batch size 65400, episode return 53.1M, loss 642944.8\n",
      "Episode 328, epsilon   0.01, batch size 65600, episode return 64.4M, loss 561456.1\n",
      "Episode 329, epsilon   0.01, batch size 65800, episode return 26.0M, loss 3626913.0\n",
      "Episode 330, epsilon   0.01, batch size 66000, episode return 22.8M, loss 4291986.5\n",
      "Episode 331, epsilon   0.01, batch size 66200, episode return 54.9M, loss 7960507.0\n",
      "Episode 332, epsilon   0.01, batch size 66400, episode return 68.3M, loss 2274218.2\n",
      "Episode 333, epsilon   0.01, batch size 66600, episode return 62.1M, loss 850295.6\n",
      "Episode 334, epsilon   0.01, batch size 66800, episode return 48.6M, loss 1711298.8\n",
      "Episode 335, epsilon   0.01, batch size 67000, episode return 63.0M, loss 1998193.8\n",
      "Episode 336, epsilon   0.01, batch size 67200, episode return 30.7M, loss 797083.1\n",
      "Episode 337, epsilon   0.01, batch size 67400, episode return 35.8M, loss 816055.0\n",
      "Episode 338, epsilon   0.01, batch size 67600, episode return 11.0M, loss 887977.9\n",
      "Episode 339, epsilon   0.01, batch size 67800, episode return 64.0M, loss 3137250.0\n",
      "Episode 340, epsilon   0.01, batch size 68000, episode return 42.6M, loss 1247409.6\n",
      "Episode 341, epsilon   0.01, batch size 68200, episode return 61.1M, loss 428851.6\n",
      "Episode 342, epsilon   0.01, batch size 68400, episode return 13.9M, loss 1325991.6\n",
      "Episode 343, epsilon   0.01, batch size 68600, episode return 35.6M, loss 2326200.0\n",
      "Episode 344, epsilon   0.01, batch size 68800, episode return  5.6M, loss 3255018.5\n",
      "Episode 345, epsilon   0.01, batch size 69000, episode return 25.4M, loss 89922720.0\n",
      "Episode 346, epsilon   0.01, batch size 69200, episode return 13.7M, loss 12435285.0\n",
      "Episode 347, epsilon   0.01, batch size 69400, episode return 31.7M, loss 552455.9\n",
      "Episode 348, epsilon   0.01, batch size 69600, episode return 19.6M, loss 411077.7\n",
      "Episode 349, epsilon   0.01, batch size 69800, episode return 79.5M, loss 99559024.0\n",
      "Episode 350, epsilon   0.01, batch size 70000, episode return 19.8M, loss 2924094.0\n",
      "Episode 351, epsilon   0.01, batch size 70200, episode return 24.2M, loss 3422023.0\n",
      "Episode 352, epsilon   0.01, batch size 70400, episode return 95.0M, loss 6459368.5\n",
      "Episode 353, epsilon   0.01, batch size 70600, episode return 10.7M, loss 4500310.0\n",
      "Episode 354, epsilon   0.01, batch size 70800, episode return 30.7M, loss 4283867.5\n",
      "Episode 355, epsilon   0.01, batch size 71000, episode return 81.8M, loss 27672392.0\n",
      "Episode 356, epsilon   0.01, batch size 71200, episode return  9.2M, loss 2547826.5\n",
      "Episode 357, epsilon   0.01, batch size 71400, episode return 17.6M, loss 976861.2\n",
      "Episode 358, epsilon   0.01, batch size 71600, episode return 34.2M, loss 1119983.2\n",
      "Episode 359, epsilon   0.01, batch size 71800, episode return 13.7M, loss 1144301.5\n",
      "Episode 360, epsilon   0.01, batch size 72000, episode return 46.3M, loss 3726926.8\n",
      "Episode 361, epsilon   0.01, batch size 72200, episode return 141.8M, loss 4170092.0\n",
      "Episode 362, epsilon   0.01, batch size 72400, episode return 20.6M, loss 464303.2\n",
      "Episode 363, epsilon   0.01, batch size 72600, episode return 15.7M, loss 2769186.5\n",
      "Episode 364, epsilon   0.01, batch size 72800, episode return  7.9M, loss 6641053.5\n",
      "Episode 365, epsilon   0.01, batch size 73000, episode return 19.8M, loss 127331376.0\n",
      "Episode 366, epsilon   0.01, batch size 73200, episode return 21.6M, loss 2726551.5\n",
      "Episode 367, epsilon   0.01, batch size 73400, episode return 121.0M, loss 1013424.9\n",
      "Episode 368, epsilon   0.01, batch size 73600, episode return 114.4M, loss 7665788.5\n",
      "Episode 369, epsilon   0.01, batch size 73800, episode return 145.7M, loss 4311256.0\n",
      "Episode 370, epsilon   0.01, batch size 74000, episode return 10.4M, loss 3737851.5\n",
      "Episode 371, epsilon   0.01, batch size 74200, episode return 53.4M, loss 816319.2\n",
      "Episode 372, epsilon   0.01, batch size 74400, episode return 103.5M, loss 721863.7\n",
      "Episode 373, epsilon   0.01, batch size 74600, episode return  3.6M, loss 945241.8\n",
      "Episode 374, epsilon   0.01, batch size 74800, episode return 10.7M, loss 2116924.8\n",
      "Episode 375, epsilon   0.01, batch size 75000, episode return 710.2M, loss 447230.1\n",
      "Episode 376, epsilon   0.01, batch size 75200, episode return 211.1M, loss 753268.8\n",
      "Episode 377, epsilon   0.01, batch size 75400, episode return 20.0M, loss 108603464.0\n",
      "Episode 378, epsilon   0.01, batch size 75600, episode return 11.0M, loss 7829811.0\n",
      "Episode 379, epsilon   0.01, batch size 75800, episode return  9.5M, loss 26640636.0\n",
      "Episode 380, epsilon   0.01, batch size 76000, episode return 351.1M, loss 282550.4\n",
      "Episode 381, epsilon   0.01, batch size 76200, episode return 200.6M, loss 373739.4\n",
      "Episode 382, epsilon   0.01, batch size 76400, episode return  2.8M, loss 1182576.2\n",
      "Episode 383, epsilon   0.01, batch size 76600, episode return  4.7M, loss 528287.6\n",
      "Episode 384, epsilon   0.01, batch size 76800, episode return  6.4M, loss 545135.8\n",
      "Episode 385, epsilon   0.01, batch size 77000, episode return  3.6M, loss 2099012.8\n",
      "Episode 386, epsilon   0.01, batch size 77200, episode return 10.1M, loss 368942.0\n",
      "Episode 387, epsilon   0.01, batch size 77400, episode return 16.1M, loss 211690.1\n",
      "Episode 388, epsilon   0.01, batch size 77600, episode return  6.2M, loss 168451.7\n",
      "Episode 389, epsilon   0.01, batch size 77800, episode return  6.2M, loss 453804.0\n",
      "Episode 390, epsilon   0.01, batch size 78000, episode return 27.6M, loss 120330.7\n",
      "Episode 391, epsilon   0.01, batch size 78200, episode return 28.0M, loss 551040.0\n",
      "Episode 392, epsilon   0.01, batch size 78400, episode return  7.4M, loss 1026103.8\n",
      "Episode 393, epsilon   0.01, batch size 78600, episode return  6.8M, loss 205384.0\n",
      "Episode 394, epsilon   0.01, batch size 78800, episode return 10.5M, loss 208217.7\n",
      "Episode 395, epsilon   0.01, batch size 79000, episode return  6.2M, loss 244625.4\n",
      "Episode 396, epsilon   0.01, batch size 79200, episode return  6.3M, loss 609996.4\n",
      "Episode 397, epsilon   0.01, batch size 79400, episode return  9.8M, loss 331928.5\n",
      "Episode 398, epsilon   0.01, batch size 79600, episode return 14.1M, loss 419016.6\n",
      "Episode 399, epsilon   0.01, batch size 79800, episode return 10.4M, loss 371557.4\n",
      "Episode 400, epsilon   0.01, batch size 80000, episode return  6.7M, loss 1123802.2\n",
      "Episode 401, epsilon   0.01, batch size 80200, episode return 14.0M, loss 6533360.0\n",
      "Episode 402, epsilon   0.01, batch size 80400, episode return  8.0M, loss 270887.4\n",
      "Episode 403, epsilon   0.01, batch size 80600, episode return  7.1M, loss 172431.5\n",
      "Episode 404, epsilon   0.01, batch size 80800, episode return 16.2M, loss 1050723.9\n",
      "Episode 405, epsilon   0.01, batch size 81000, episode return 21.2M, loss 436359.1\n",
      "Episode 406, epsilon   0.01, batch size 81200, episode return 20.0M, loss 1400812.0\n",
      "Episode 407, epsilon   0.01, batch size 81400, episode return 12.0M, loss 444943.9\n",
      "Episode 408, epsilon   0.01, batch size 81600, episode return 19.2M, loss 677098.1\n",
      "Episode 409, epsilon   0.01, batch size 81800, episode return 12.9M, loss 727861.9\n",
      "Episode 410, epsilon   0.01, batch size 82000, episode return 14.9M, loss 570230.1\n",
      "Episode 411, epsilon   0.01, batch size 82200, episode return 10.7M, loss 170413.3\n",
      "Episode 412, epsilon   0.01, batch size 82400, episode return 604.1M, loss 114592.9\n",
      "Episode 413, epsilon   0.01, batch size 82600, episode return 123.4M, loss 214208.9\n",
      "Episode 414, epsilon   0.01, batch size 82800, episode return 12.7M, loss 251785.9\n",
      "Episode 415, epsilon   0.01, batch size 83000, episode return 20.1M, loss 131664.8\n",
      "Episode 416, epsilon   0.01, batch size 83200, episode return 84.3M, loss 105951.4\n",
      "Episode 417, epsilon   0.01, batch size 83400, episode return 11.1M, loss 138900.7\n",
      "Episode 418, epsilon   0.01, batch size 83600, episode return 10.2M, loss 278839.4\n",
      "Episode 419, epsilon   0.01, batch size 83800, episode return  7.5M, loss 425553.2\n",
      "Episode 420, epsilon   0.01, batch size 84000, episode return 50.6M, loss 43701.9\n",
      "Episode 421, epsilon   0.01, batch size 84200, episode return 11.3M, loss 445312.6\n",
      "Episode 422, epsilon   0.01, batch size 84400, episode return 539.9M, loss 1359391.2\n",
      "Episode 423, epsilon   0.01, batch size 84600, episode return 62.1M, loss 22287862.0\n",
      "Episode 424, epsilon   0.01, batch size 84800, episode return 27.2M, loss 276753.4\n",
      "Episode 425, epsilon   0.01, batch size 85000, episode return 48.9M, loss 204985.1\n",
      "Episode 426, epsilon   0.01, batch size 85200, episode return 63.5M, loss 272125.9\n",
      "Episode 427, epsilon   0.01, batch size 85400, episode return 2797.9M, loss 317816.2\n",
      "Episode 428, epsilon   0.01, batch size 85600, episode return 2625.7M, loss 153427.9\n",
      "Episode 429, epsilon   0.01, batch size 85800, episode return 149.2M, loss 97163.4\n",
      "Episode 430, epsilon   0.01, batch size 86000, episode return 911.7M, loss 74657152.0\n",
      "Episode 431, epsilon   0.01, batch size 86200, episode return 72.9M, loss 190480.0\n",
      "Episode 432, epsilon   0.01, batch size 86400, episode return 156.6M, loss 171857.2\n",
      "Episode 433, epsilon   0.01, batch size 86600, episode return 111.0M, loss 148920.9\n",
      "Episode 434, epsilon   0.01, batch size 86800, episode return 124.6M, loss 100494.7\n",
      "Episode 435, epsilon   0.01, batch size 87000, episode return 534.4M, loss 198625.0\n",
      "Episode 436, epsilon   0.01, batch size 87200, episode return 607.1M, loss 419956.3\n",
      "Episode 437, epsilon   0.01, batch size 87400, episode return 281.8M, loss 235422.8\n",
      "Evaluation deterministic reward 7655.6M\n",
      "Episode 438, epsilon   0.01, batch size 87600, episode return 258.5M, loss 73196.6\n",
      "Episode 439, epsilon   0.01, batch size 87800, episode return 268.0M, loss 252494.2\n",
      "Episode 440, epsilon   0.01, batch size 88000, episode return 1524.8M, loss 143372000.0\n",
      "Episode 441, epsilon   0.01, batch size 88200, episode return 568.5M, loss 223064.1\n",
      "Episode 442, epsilon   0.01, batch size 88400, episode return  9.2M, loss 1579811.5\n",
      "Episode 443, epsilon   0.01, batch size 88600, episode return 1130.4M, loss 79197.6\n",
      "Episode 444, epsilon   0.01, batch size 88800, episode return 10.6M, loss 255481.6\n",
      "Episode 445, epsilon   0.01, batch size 89000, episode return  3.6M, loss 1433934.4\n",
      "Episode 446, epsilon   0.01, batch size 89200, episode return  9.9M, loss 387700.3\n",
      "Episode 447, epsilon   0.01, batch size 89400, episode return  5.4M, loss 482513.7\n",
      "Episode 448, epsilon   0.01, batch size 89600, episode return  7.9M, loss 75109.6\n",
      "Episode 449, epsilon   0.01, batch size 89800, episode return  5.4M, loss 81445.8\n",
      "Episode 450, epsilon   0.01, batch size 90000, episode return 15.0M, loss 42185.5\n",
      "Episode 451, epsilon   0.01, batch size 90200, episode return 21.5M, loss 31018.1\n",
      "Episode 452, epsilon   0.01, batch size 90400, episode return 11.4M, loss 108114.3\n",
      "Episode 453, epsilon   0.01, batch size 90600, episode return 2819.6M, loss 481608.4\n",
      "Episode 454, epsilon   0.01, batch size 90800, episode return 1006.3M, loss 317725.9\n",
      "Episode 455, epsilon   0.01, batch size 91000, episode return  3.5M, loss 470453.6\n",
      "Episode 456, epsilon   0.01, batch size 91200, episode return 30.9M, loss 72785616.0\n",
      "Episode 457, epsilon   0.01, batch size 91400, episode return  5.0M, loss 8804966.0\n",
      "Episode 458, epsilon   0.01, batch size 91600, episode return 79.3M, loss 10531478.0\n",
      "Episode 459, epsilon   0.01, batch size 91800, episode return  4.6M, loss 1105635.0\n",
      "Episode 460, epsilon   0.01, batch size 92000, episode return  2.0M, loss 2209645.0\n",
      "Episode 461, epsilon   0.01, batch size 92200, episode return  3.1M, loss 534656.9\n",
      "Episode 462, epsilon   0.01, batch size 92400, episode return  3.0M, loss 318744.1\n",
      "Episode 463, epsilon   0.01, batch size 92600, episode return  5.7M, loss 652611.6\n",
      "Episode 464, epsilon   0.01, batch size 92800, episode return  6.2M, loss 746410.8\n",
      "Episode 465, epsilon   0.01, batch size 93000, episode return  7.5M, loss 174306048.0\n",
      "Episode 466, epsilon   0.01, batch size 93200, episode return  7.7M, loss 502791.6\n",
      "Episode 467, epsilon   0.01, batch size 93400, episode return 37.5M, loss 361804.0\n",
      "Episode 468, epsilon   0.01, batch size 93600, episode return  9.2M, loss 253942.3\n",
      "Episode 469, epsilon   0.01, batch size 93800, episode return  7.2M, loss 507115.2\n",
      "Episode 470, epsilon   0.01, batch size 94000, episode return 11.5M, loss 1901002.9\n",
      "Episode 471, epsilon   0.01, batch size 94200, episode return  8.8M, loss 370373.6\n",
      "Episode 472, epsilon   0.01, batch size 94400, episode return 14.2M, loss 347313.8\n",
      "Episode 473, epsilon   0.01, batch size 94600, episode return 16.2M, loss 170234.7\n",
      "Episode 474, epsilon   0.01, batch size 94800, episode return  5.5M, loss 104166.2\n",
      "Episode 475, epsilon   0.01, batch size 95000, episode return  6.4M, loss 446311.3\n",
      "Episode 476, epsilon   0.01, batch size 95200, episode return 16.4M, loss 759586.9\n",
      "Episode 477, epsilon   0.01, batch size 95400, episode return 48.8M, loss 960695.4\n",
      "Episode 478, epsilon   0.01, batch size 95600, episode return  7.5M, loss 670601.6\n",
      "Episode 479, epsilon   0.01, batch size 95800, episode return 12.9M, loss 1502216.9\n",
      "Episode 480, epsilon   0.01, batch size 96000, episode return  6.8M, loss 181782.7\n",
      "Episode 481, epsilon   0.01, batch size 96200, episode return 17.2M, loss 183099.4\n",
      "Episode 482, epsilon   0.01, batch size 96400, episode return  4.9M, loss 184107.3\n",
      "Episode 483, epsilon   0.01, batch size 96600, episode return  6.2M, loss 717154.8\n",
      "Episode 484, epsilon   0.01, batch size 96800, episode return 15.2M, loss 6756743.0\n",
      "Episode 485, epsilon   0.01, batch size 97000, episode return 16.5M, loss 697993.0\n",
      "Episode 486, epsilon   0.01, batch size 97200, episode return  9.1M, loss 599852.1\n",
      "Episode 487, epsilon   0.01, batch size 97400, episode return 17.3M, loss 271704.6\n",
      "Episode 488, epsilon   0.01, batch size 97600, episode return 12.4M, loss 556488.9\n",
      "Episode 489, epsilon   0.01, batch size 97800, episode return 24.0M, loss 131795.0\n",
      "Episode 490, epsilon   0.01, batch size 98000, episode return 24.0M, loss 154073.5\n",
      "Episode 491, epsilon   0.01, batch size 98200, episode return 15.8M, loss 242164.5\n",
      "Episode 492, epsilon   0.01, batch size 98400, episode return 25.3M, loss 73936.6\n",
      "Episode 493, epsilon   0.01, batch size 98600, episode return 18.5M, loss 312579.4\n",
      "Episode 494, epsilon   0.01, batch size 98800, episode return 32.0M, loss 186090.2\n",
      "Episode 495, epsilon   0.01, batch size 99000, episode return 33.0M, loss 185839.7\n",
      "Episode 496, epsilon   0.01, batch size 99200, episode return 27.1M, loss 161234.4\n",
      "Episode 497, epsilon   0.01, batch size 99400, episode return 38.0M, loss 185859.2\n",
      "Episode 498, epsilon   0.01, batch size 99600, episode return 34.6M, loss 165811.9\n",
      "Episode 499, epsilon   0.01, batch size 99800, episode return 162.7M, loss 76975.6\n",
      "Episode 500, epsilon   0.01, batch size 100000, episode return 42.7M, loss 137440.5\n"
     ]
    }
   ],
   "source": [
    "env = TimeLimit(HIVPatient(), max_episode_steps=200)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Declare network\n",
    "state_dim = env.observation_space.shape[0]\n",
    "n_action = env.action_space.n \n",
    "nb_neurons=128\n",
    "config = {'nb_actions': n_action, 'learning_rate': 0.01,\n",
    "          'gamma': 0.95, 'buffer_size': 100_000,\n",
    "          'epsilon_min': 0.01, 'epsilon_max': 1,\n",
    "          'epsilon_decay_period': 5_000, 'epsilon_delay_decay': 1,\n",
    "          'batch_size': 32, 'model_path': 'best_model_standard_scaling.pth',\n",
    "          'scaling': 'standard', 'criterion': torch.nn.SmoothL1Loss()}\n",
    "\n",
    "##Train and load the best model\n",
    "DQN = torch.nn.Sequential(nn.Linear(state_dim, nb_neurons),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(nb_neurons, nb_neurons),\n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(nb_neurons, n_action)).to(device)\n",
    "\n",
    "\n",
    "#load the best model\n",
    "DQN.load_state_dict(torch.load('best_model_standard_scaling.pth', weights_only=True))\n",
    "agent = dqn_agent(config, DQN, load=True)\n",
    "scores = agent.train(env, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score agent: 7655.63M\n",
      "Score agent DR: 1398.73M\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluate_HIV, evaluate_HIV_population\n",
    "from train import ProjectAgent  # Replace DummyAgent with your agent implementation\n",
    "\n",
    "agent = ProjectAgent()\n",
    "agent.load()\n",
    "# Evaluate agent and write score.\n",
    "score_agent: float = evaluate_HIV(agent=agent, nb_episode=5)\n",
    "score_agent_dr: float = evaluate_HIV_population(agent=agent, nb_episode=20)\n",
    "print(f\"Score agent: {score_agent/1_000_000:.2f}M\")\n",
    "print(f\"Score agent DR: {score_agent_dr/1_000_000:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ActorCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from actor_critic import Actor, Critic, ActorCritic, evaluate_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct variable assignments instead of argument parsing\n",
    "class Args:\n",
    "     def __init__(self, device=\"cpu\", load=False, plot=True, model='reinforce_hiv/model.pt', \n",
    "                  lr=0.01, episodes=1000, gamma=0.95, scaling='standard'): \n",
    "          self.device = device  # cuda device\n",
    "          self.load = load  # if loading an existing model\n",
    "          self.plot = plot  # if plotting an existing model\n",
    "          self.model = model  # model path\n",
    "          self.lr = lr  # learning rate\n",
    "          self.episodes = episodes  # number of episodes\n",
    "          self.gamma = gamma  # discount factor\n",
    "          self.scaling = scaling  # scaling method\n",
    "\n",
    "class Runner(): \n",
    "     def __init__(self, env, logs=\"hiv\", args=Args()):\n",
    "          self.device = args.device\n",
    "          self.actor = Actor(env.observation_space.shape[0], env.action_space.n).to(self.device)\n",
    "          self.critic = Critic(env.observation_space.shape[0]).to(self.device)\n",
    "          self.a_opt = optim.Adam(self.actor.parameters(), lr=args.lr)\n",
    "          self.c_opt = optim.Adam(self.critic.parameters(), lr=args.lr)\n",
    "          self.gamma = args.gamma\n",
    "          self.logs = logs\n",
    "          self.writer = SummaryWriter(logs)\n",
    "          self.entropy = 0\n",
    "          self.plots = {\"Actor Loss\": [], \"Critic Loss\": [], \"Reward\": [], \"Mean Reward\": []}\n",
    "          self.load = args.load\n",
    "          self.env = env\n",
    "          self.states_means = np.load('states_means.npy')\n",
    "          self.states_stds = np.load('states_stds.npy')\n",
    "          self.scaling = args.scaling\n",
    "          self.criterion = torch.nn.SmoothL1Loss()\n",
    "          if args.load: \n",
    "               ac = ActorCritic(self.actor, self.critic)\n",
    "               ac.load_state_dict(torch.load(args.model))\n",
    "               self.actor = ac.actor\n",
    "               self.critic = ac.critic\n",
    "\n",
    "     def env_step(self, action):\n",
    "          state, reward, done, trunc, log = self.env.step(action)\n",
    "          return torch.FloatTensor([state]).to(self.device), torch.FloatTensor([reward]).to(self.device), done, trunc, log\n",
    "\n",
    "     def select_action(self, state):\n",
    "          # Convert state to tensor\n",
    "          probs = self.actor(state)\n",
    "          c = Categorical(probs)\n",
    "          action = c.sample()\n",
    "\n",
    "          # Place log probabilities into the policy history log\\pi(a | s)\n",
    "          if self.actor.policy_history.dim() != 0: \n",
    "                self.actor.policy_history = torch.cat([self.actor.policy_history, c.log_prob(action)])\n",
    "          else: \n",
    "                self.actor.policy_history = (c.log_prob(action))\n",
    "     \n",
    "          return action\n",
    "  \n",
    "     def estimate_value(self, state): \n",
    "          pred = self.critic(state).squeeze(0)\n",
    "          if self.critic.value_history.dim() != 0: \n",
    "               self.critic.value_history = torch.cat([self.critic.value_history, pred])\n",
    "          else: \n",
    "               self.critic.policy_history = (pred)\n",
    "\n",
    "     def update_a2c(self):\n",
    "          R = 0\n",
    "          q_vals = []\n",
    "\n",
    "          # \"Unroll\" the rewards, apply gamma\n",
    "          for r in self.actor.reward_episode[::-1]: \n",
    "               R = r + self.gamma * R\n",
    "               q_vals.insert(0, R)\n",
    "     \n",
    "          q_vals = torch.FloatTensor(q_vals).to(self.device)\n",
    "          values = self.critic.value_history\n",
    "          log_probs = self.actor.policy_history\n",
    "     \n",
    "          advantage = q_vals - values\n",
    "  \n",
    "          self.c_opt.zero_grad()\n",
    "          critic_loss = 0.05*self.criterion(values, q_vals)\n",
    "          critic_loss.backward()\n",
    "          self.c_opt.step()\n",
    "\n",
    "          self.a_opt.zero_grad()\n",
    "          actor_loss = -(log_probs * advantage.detach()).mean() + 0.0001 * self.entropy\n",
    "          actor_loss.backward()\n",
    "          self.a_opt.step()\n",
    "\n",
    "          self.actor.reward_episode = []\n",
    "          self.actor.policy_history = Variable(torch.Tensor()).to(self.device)\n",
    "          self.critic.value_history = Variable(torch.Tensor()).to(self.device)\n",
    "     \n",
    "          return actor_loss, critic_loss\n",
    "  \n",
    "     def train(self, episodes=200, smooth=10):\n",
    "          smoothed_reward = []\n",
    "          best_deterministic_reward = -np.inf\n",
    "          if self.load:\n",
    "            best_deterministic_reward = evaluate_actor(self.actor, self.env, 1, scaling=self.scaling)/1_000_000\n",
    "            print(f\"Loaded model with deterministic reward {best_deterministic_reward:.2f}M\")\n",
    "          for episode in range(episodes): \n",
    "                rewards = 0\n",
    "                state = self.env.reset()[0]\n",
    "                state = (state - self.states_means) / self.states_stds\n",
    "                self.entropy = 0\n",
    "                done = False\n",
    "                true_reward = 0\n",
    "\n",
    "                for step in range(200): \n",
    "                    self.estimate_value(state)\n",
    "          \n",
    "                    policy = self.actor(state).cpu().detach().numpy()\n",
    "                    action = self.select_action(state)\n",
    "                    e = -np.sum(np.mean(policy) * np.log(policy))\n",
    "                    self.entropy += e\n",
    "\n",
    "                    state, reward, done, trunc, _ = self.env.step(action.data[0].item())\n",
    "                    state = (state - self.states_means) / self.states_stds\n",
    "                    true_reward += reward/1_000_000\n",
    "                    reward= np.log10(reward + 100_000)\n",
    "                    rewards += reward\n",
    "\n",
    "                    self.actor.reward_episode.append(reward)\n",
    "\n",
    "                    if done or trunc:\n",
    "                         break\n",
    "                deterministic_reward = evaluate_actor(self.actor, self.env, 1, scaling=self.scaling)/1_000_000\n",
    "                if deterministic_reward > best_deterministic_reward:\n",
    "                    best_deterministic_reward = deterministic_reward\n",
    "                    ac = ActorCritic(self.actor, self.critic)\n",
    "                    torch.save(ac.state_dict(), '%s/model_a2c.pt' % self.logs)\n",
    "                    torch.save(best_deterministic_reward, self.logs + '/best_deterministic_reward_a2c.pth')\n",
    "                    print(\"Evaluation deterministic reward\", f\"{deterministic_reward:.1f}M\")\n",
    "\n",
    "                smoothed_reward.append(true_reward)\n",
    "                if len(smoothed_reward) > smooth: \n",
    "                    smoothed_reward = smoothed_reward[-1*smooth: -1]\n",
    "\n",
    "                a_loss, c_loss = self.update_a2c()\n",
    "        \n",
    "                self.writer.add_scalar(\"Critic Loss\", c_loss, episode)\n",
    "                self.writer.add_scalar(\"Actor Loss\", a_loss, episode)\n",
    "                self.writer.add_scalar(\"Reward\", true_reward, episode)\n",
    "                self.writer.add_scalar(\"Mean Reward\", np.mean(smoothed_reward), episode)\n",
    "\n",
    "                self.plots[\"Critic Loss\"].append(c_loss.item() * 100)\n",
    "                self.plots[\"Actor Loss\"].append(a_loss.item())\n",
    "                self.plots[\"Reward\"].append(true_reward)\n",
    "                self.plots[\"Mean Reward\"].append(np.mean(smoothed_reward))\n",
    "\n",
    "                if episode % 1 == 0: \n",
    "                    print(\"\\tEpisode {} \\t Final Reward {:.2f}M \\t Average Reward: {:.2f}M\".format(episode, true_reward, np.mean(smoothed_reward)),\n",
    "                          \"Actor Loss: \", a_loss.item(), \"Critic Loss: \", c_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]\tTraining Beginning ...\n",
      "Evaluation deterministic reward 3.1M\n",
      "\tEpisode 0 \t Final Reward 9.40M \t Average Reward: 9.40M Actor Loss:  401.8038635253906 Critic Loss:  14.735630989074707\n",
      "Evaluation deterministic reward 5.2M\n",
      "\tEpisode 1 \t Final Reward 8.83M \t Average Reward: 9.11M Actor Loss:  353.3734130859375 Critic Loss:  14.66199779510498\n",
      "\tEpisode 2 \t Final Reward 6.07M \t Average Reward: 8.10M Actor Loss:  295.3632507324219 Critic Loss:  14.434295654296875\n",
      "\tEpisode 3 \t Final Reward 6.16M \t Average Reward: 7.61M Actor Loss:  258.5687561035156 Critic Loss:  14.362095832824707\n",
      "\tEpisode 4 \t Final Reward 5.50M \t Average Reward: 7.19M Actor Loss:  234.49424743652344 Critic Loss:  14.18640422821045\n",
      "\tEpisode 5 \t Final Reward 4.38M \t Average Reward: 6.72M Actor Loss:  196.78842163085938 Critic Loss:  13.936531066894531\n",
      "\tEpisode 6 \t Final Reward 3.91M \t Average Reward: 6.32M Actor Loss:  181.99671936035156 Critic Loss:  13.653963088989258\n",
      "\tEpisode 7 \t Final Reward 3.79M \t Average Reward: 6.01M Actor Loss:  178.2272491455078 Critic Loss:  13.3501558303833\n",
      "\tEpisode 8 \t Final Reward 3.51M \t Average Reward: 5.73M Actor Loss:  147.54006958007812 Critic Loss:  12.97442626953125\n",
      "\tEpisode 9 \t Final Reward 3.39M \t Average Reward: 5.49M Actor Loss:  139.92469787597656 Critic Loss:  12.559429168701172\n",
      "\tEpisode 10 \t Final Reward 3.44M \t Average Reward: 5.06M Actor Loss:  143.81871032714844 Critic Loss:  12.05667781829834\n",
      "\tEpisode 11 \t Final Reward 3.16M \t Average Reward: 4.87M Actor Loss:  101.30126190185547 Critic Loss:  11.510472297668457\n",
      "\tEpisode 12 \t Final Reward 3.29M \t Average Reward: 4.43M Actor Loss:  122.15668487548828 Critic Loss:  10.873730659484863\n",
      "\tEpisode 13 \t Final Reward 3.29M \t Average Reward: 4.32M Actor Loss:  127.5863037109375 Critic Loss:  10.17223072052002\n",
      "\tEpisode 14 \t Final Reward 3.47M \t Average Reward: 4.12M Actor Loss:  116.5988998413086 Critic Loss:  9.50594711303711\n",
      "\tEpisode 15 \t Final Reward 3.60M \t Average Reward: 4.07M Actor Loss:  87.26435089111328 Critic Loss:  8.761981964111328\n",
      "\tEpisode 16 \t Final Reward 3.71M \t Average Reward: 3.84M Actor Loss:  64.52439880371094 Critic Loss:  7.995019435882568\n",
      "\tEpisode 17 \t Final Reward 3.74M \t Average Reward: 3.83M Actor Loss:  30.52814292907715 Critic Loss:  7.2329559326171875\n",
      "\tEpisode 18 \t Final Reward 3.71M \t Average Reward: 3.64M Actor Loss:  10.836967468261719 Critic Loss:  6.1566853523254395\n",
      "\tEpisode 19 \t Final Reward 3.67M \t Average Reward: 3.65M Actor Loss:  -10.199156761169434 Critic Loss:  5.337830066680908\n",
      "\tEpisode 20 \t Final Reward 3.69M \t Average Reward: 3.56M Actor Loss:  -0.35936903953552246 Critic Loss:  5.020333766937256\n",
      "\tEpisode 21 \t Final Reward 3.73M \t Average Reward: 3.58M Actor Loss:  1.2298434972763062 Critic Loss:  5.550028324127197\n",
      "\tEpisode 22 \t Final Reward 3.68M \t Average Reward: 3.54M Actor Loss:  -5.339248180389404 Critic Loss:  5.9196696281433105\n",
      "\tEpisode 23 \t Final Reward 3.66M \t Average Reward: 3.56M Actor Loss:  -2.313746452331543 Critic Loss:  6.8984575271606445\n",
      "\tEpisode 24 \t Final Reward 3.72M \t Average Reward: 3.53M Actor Loss:  -25.531749725341797 Critic Loss:  6.072116374969482\n",
      "\tEpisode 25 \t Final Reward 3.65M \t Average Reward: 3.54M Actor Loss:  -1.0805509090423584 Critic Loss:  6.2132792472839355\n",
      "\tEpisode 26 \t Final Reward 3.68M \t Average Reward: 3.54M Actor Loss:  -5.864734172821045 Critic Loss:  5.458099365234375\n",
      "\tEpisode 27 \t Final Reward 3.68M \t Average Reward: 3.56M Actor Loss:  -19.64406394958496 Critic Loss:  4.974520683288574\n",
      "\tEpisode 28 \t Final Reward 3.68M \t Average Reward: 3.58M Actor Loss:  0.6019951701164246 Critic Loss:  5.155281066894531\n",
      "\tEpisode 29 \t Final Reward 3.65M \t Average Reward: 3.58M Actor Loss:  0.17954932153224945 Critic Loss:  5.049047946929932\n",
      "\tEpisode 30 \t Final Reward 3.65M \t Average Reward: 3.63M Actor Loss:  0.23089970648288727 Critic Loss:  5.1196088790893555\n",
      "\tEpisode 31 \t Final Reward 3.65M \t Average Reward: 3.63M Actor Loss:  0.2475980818271637 Critic Loss:  5.231273174285889\n",
      "\tEpisode 32 \t Final Reward 3.65M \t Average Reward: 3.67M Actor Loss:  0.2538209557533264 Critic Loss:  5.342918395996094\n",
      "\tEpisode 33 \t Final Reward 3.65M \t Average Reward: 3.67M Actor Loss:  0.25778403878211975 Critic Loss:  5.428779125213623\n",
      "\tEpisode 34 \t Final Reward 3.65M \t Average Reward: 3.68M Actor Loss:  0.2618360221385956 Critic Loss:  5.475940227508545\n",
      "\tEpisode 35 \t Final Reward 3.65M \t Average Reward: 3.67M Actor Loss:  0.2664303183555603 Critic Loss:  5.481013298034668\n",
      "\tEpisode 36 \t Final Reward 3.65M \t Average Reward: 3.67M Actor Loss:  0.2714279592037201 Critic Loss:  5.4470391273498535\n",
      "\tEpisode 37 \t Final Reward 3.65M \t Average Reward: 3.67M Actor Loss:  0.27660804986953735 Critic Loss:  5.38176965713501\n",
      "\tEpisode 38 \t Final Reward 3.65M \t Average Reward: 3.66M Actor Loss:  0.28178533911705017 Critic Loss:  5.296428203582764\n",
      "\tEpisode 39 \t Final Reward 3.65M \t Average Reward: 3.66M Actor Loss:  0.2868236005306244 Critic Loss:  5.204814434051514\n",
      "\tEpisode 40 \t Final Reward 3.65M \t Average Reward: 3.66M Actor Loss:  0.2916393578052521 Critic Loss:  5.12175178527832\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m runner \u001b[38;5;241m=\u001b[39m Runner(env, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreinforce_hiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39margs)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Train]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTraining Beginning ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepisodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[End]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDone. Congratulations!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[55], line 109\u001b[0m, in \u001b[0;36mRunner.train\u001b[1;34m(self, episodes, smooth)\u001b[0m\n\u001b[0;32m    106\u001b[0m true_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m): \n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor(state)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    112\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_action(state)\n",
      "Cell \u001b[1;32mIn[55], line 57\u001b[0m, in \u001b[0;36mRunner.estimate_value\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mestimate_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, state): \n\u001b[1;32m---> 57\u001b[0m      pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     58\u001b[0m      \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mvalue_history\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[0;32m     59\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mvalue_history \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mvalue_history, pred])\n",
      "File \u001b[1;32mc:\\Users\\habib\\anaconda3\\envs\\rl_hw\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\habib\\anaconda3\\envs\\rl_hw\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\habib\\Documents\\Mohammed-Yassine\\2024_2025\\MVA\\RL\\Final Project\\mva-rl-assignment-mohammed-yassinehabibi\\src\\actor_critic.py:49\u001b[0m, in \u001b[0;36mCritic.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[1;32m---> 49\u001b[0m      x \u001b[38;5;241m=\u001b[39m Variable(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     50\u001b[0m      x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(x))\n\u001b[0;32m     51\u001b[0m      x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(x))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "env = TimeLimit(HIVPatient(), max_episode_steps=200)\n",
    "\n",
    "args = Args(device=device, load=False, \n",
    "          plot=True, model='reinforce_hiv/model.pt', \n",
    "          lr=0.01, episodes=500, gamma=0.99, scaling='standard')\n",
    "\n",
    "runner = Runner(env, logs=\"reinforce_hiv\", args=args)\n",
    "\n",
    "print(\"[Train]\\tTraining Beginning ...\")\n",
    "runner.train(args.episodes)\n",
    "print(\"[End]\\tDone. Congratulations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5426976.930085338)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_HIV = partial(evaluate_actor, env=env)\n",
    "score_agent: float = evaluate_HIV(agent=actor, nb_episode=1)\n",
    "score_agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
